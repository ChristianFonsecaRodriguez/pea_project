2023-10-31 22:15:10,784:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-10-31 22:15:10,785:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-10-31 22:15:10,785:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-10-31 22:15:10,785:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-10-31 22:16:52,279:INFO:PyCaret RegressionExperiment
2023-10-31 22:16:52,280:INFO:Logging name: reg-default-name
2023-10-31 22:16:52,280:INFO:ML Usecase: MLUsecase.REGRESSION
2023-10-31 22:16:52,280:INFO:version 3.1.0
2023-10-31 22:16:52,280:INFO:Initializing setup()
2023-10-31 22:16:52,280:INFO:self.USI: ee2c
2023-10-31 22:16:52,280:INFO:self._variable_keys: {'_available_plots', 'exp_name_log', 'memory', 'y_train', 'X_train', 'idx', 'transform_target_param', 'gpu_param', 'data', 'pipeline', 'target_param', 'gpu_n_jobs_param', 'fold_shuffle_param', 'X', 'logging_param', 'fold_generator', 'USI', 'log_plots_param', 'y_test', 'seed', '_ml_usecase', 'html_param', 'fold_groups_param', 'X_test', 'n_jobs_param', 'exp_id', 'y'}
2023-10-31 22:16:52,280:INFO:Checking environment
2023-10-31 22:16:52,280:INFO:python_version: 3.8.5
2023-10-31 22:16:52,280:INFO:python_build: ('tags/v3.8.5:580fbb0', 'Jul 20 2020 15:57:54')
2023-10-31 22:16:52,280:INFO:machine: AMD64
2023-10-31 22:16:52,280:INFO:platform: Windows-10-10.0.19041-SP0
2023-10-31 22:16:52,300:INFO:Memory: svmem(total=137304428544, available=99485196288, percent=27.5, used=37819232256, free=99485196288)
2023-10-31 22:16:52,301:INFO:Physical Core: 16
2023-10-31 22:16:52,301:INFO:Logical Core: 32
2023-10-31 22:16:52,301:INFO:Checking libraries
2023-10-31 22:16:52,301:INFO:System:
2023-10-31 22:16:52,301:INFO:    python: 3.8.5 (tags/v3.8.5:580fbb0, Jul 20 2020, 15:57:54) [MSC v.1924 64 bit (AMD64)]
2023-10-31 22:16:52,301:INFO:executable: d:\trabajo\dmc\202311\pea da\pea_da\scripts\python.exe
2023-10-31 22:16:52,301:INFO:   machine: Windows-10-10.0.19041-SP0
2023-10-31 22:16:52,301:INFO:PyCaret required dependencies:
2023-10-31 22:16:52,358:INFO:                 pip: 20.1.1
2023-10-31 22:16:52,358:INFO:          setuptools: 47.1.0
2023-10-31 22:16:52,359:INFO:             pycaret: 3.1.0
2023-10-31 22:16:52,359:INFO:             IPython: 8.12.3
2023-10-31 22:16:52,359:INFO:          ipywidgets: 8.1.1
2023-10-31 22:16:52,359:INFO:                tqdm: 4.66.1
2023-10-31 22:16:52,359:INFO:               numpy: 1.23.5
2023-10-31 22:16:52,359:INFO:              pandas: 1.5.3
2023-10-31 22:16:52,359:INFO:              jinja2: 3.1.2
2023-10-31 22:16:52,359:INFO:               scipy: 1.10.1
2023-10-31 22:16:52,359:INFO:              joblib: 1.3.2
2023-10-31 22:16:52,359:INFO:             sklearn: 1.2.2
2023-10-31 22:16:52,359:INFO:                pyod: 1.1.1
2023-10-31 22:16:52,359:INFO:            imblearn: 0.11.0
2023-10-31 22:16:52,359:INFO:   category_encoders: 2.6.3
2023-10-31 22:16:52,359:INFO:            lightgbm: 4.1.0
2023-10-31 22:16:52,359:INFO:               numba: 0.58.1
2023-10-31 22:16:52,359:INFO:            requests: 2.31.0
2023-10-31 22:16:52,359:INFO:          matplotlib: 3.7.3
2023-10-31 22:16:52,359:INFO:          scikitplot: 0.3.7
2023-10-31 22:16:52,359:INFO:         yellowbrick: 1.5
2023-10-31 22:16:52,359:INFO:              plotly: 5.18.0
2023-10-31 22:16:52,359:INFO:    plotly-resampler: Not installed
2023-10-31 22:16:52,359:INFO:             kaleido: 0.2.1
2023-10-31 22:16:52,359:INFO:           schemdraw: 0.15
2023-10-31 22:16:52,359:INFO:         statsmodels: 0.14.0
2023-10-31 22:16:52,360:INFO:              sktime: 0.21.1
2023-10-31 22:16:52,360:INFO:               tbats: 1.1.3
2023-10-31 22:16:52,360:INFO:            pmdarima: 2.0.4
2023-10-31 22:16:52,360:INFO:              psutil: 5.9.6
2023-10-31 22:16:52,360:INFO:          markupsafe: 2.1.3
2023-10-31 22:16:52,360:INFO:             pickle5: Not installed
2023-10-31 22:16:52,360:INFO:         cloudpickle: 2.2.1
2023-10-31 22:16:52,360:INFO:         deprecation: 2.1.0
2023-10-31 22:16:52,360:INFO:              xxhash: 3.4.1
2023-10-31 22:16:52,360:INFO:           wurlitzer: Not installed
2023-10-31 22:16:52,360:INFO:PyCaret optional dependencies:
2023-10-31 22:16:52,372:INFO:                shap: Not installed
2023-10-31 22:16:52,372:INFO:           interpret: Not installed
2023-10-31 22:16:52,372:INFO:                umap: Not installed
2023-10-31 22:16:52,372:INFO:     ydata_profiling: Not installed
2023-10-31 22:16:52,372:INFO:  explainerdashboard: Not installed
2023-10-31 22:16:52,372:INFO:             autoviz: Not installed
2023-10-31 22:16:52,372:INFO:           fairlearn: Not installed
2023-10-31 22:16:52,372:INFO:          deepchecks: Not installed
2023-10-31 22:16:52,372:INFO:             xgboost: Not installed
2023-10-31 22:16:52,372:INFO:            catboost: Not installed
2023-10-31 22:16:52,372:INFO:              kmodes: Not installed
2023-10-31 22:16:52,373:INFO:             mlxtend: Not installed
2023-10-31 22:16:52,373:INFO:       statsforecast: Not installed
2023-10-31 22:16:52,373:INFO:        tune_sklearn: Not installed
2023-10-31 22:16:52,373:INFO:                 ray: Not installed
2023-10-31 22:16:52,373:INFO:            hyperopt: Not installed
2023-10-31 22:16:52,373:INFO:              optuna: Not installed
2023-10-31 22:16:52,373:INFO:               skopt: Not installed
2023-10-31 22:16:52,373:INFO:              mlflow: 2.8.0
2023-10-31 22:16:52,373:INFO:              gradio: Not installed
2023-10-31 22:16:52,373:INFO:             fastapi: Not installed
2023-10-31 22:16:52,373:INFO:             uvicorn: Not installed
2023-10-31 22:16:52,373:INFO:              m2cgen: Not installed
2023-10-31 22:16:52,373:INFO:           evidently: Not installed
2023-10-31 22:16:52,373:INFO:               fugue: Not installed
2023-10-31 22:16:52,373:INFO:           streamlit: Not installed
2023-10-31 22:16:52,373:INFO:             prophet: Not installed
2023-10-31 22:16:52,373:INFO:None
2023-10-31 22:16:52,373:INFO:Set up data.
2023-10-31 22:16:52,386:INFO:Set up folding strategy.
2023-10-31 22:16:52,386:INFO:Set up train/test split.
2023-10-31 22:16:52,393:INFO:Set up index.
2023-10-31 22:16:52,394:INFO:Assigning column types.
2023-10-31 22:16:52,398:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2023-10-31 22:16:52,398:INFO:Engine for model 'lasso' has not been set explicitly, hence returning None.
2023-10-31 22:16:52,404:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2023-10-31 22:16:52,409:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-10-31 22:16:52,480:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-10-31 22:16:52,533:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-10-31 22:16:52,534:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-10-31 22:16:52,534:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-10-31 22:16:52,535:INFO:Engine for model 'lasso' has not been set explicitly, hence returning None.
2023-10-31 22:16:52,540:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2023-10-31 22:16:52,546:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-10-31 22:16:52,617:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-10-31 22:16:52,670:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-10-31 22:16:52,671:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-10-31 22:16:52,671:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-10-31 22:16:52,672:INFO:Engine successfully changes for model 'lasso' to 'sklearn'.
2023-10-31 22:16:52,677:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2023-10-31 22:16:52,683:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-10-31 22:16:52,754:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-10-31 22:16:52,808:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-10-31 22:16:52,809:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-10-31 22:16:52,809:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-10-31 22:16:52,815:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2023-10-31 22:16:52,821:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-10-31 22:16:52,895:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-10-31 22:16:52,949:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-10-31 22:16:52,954:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-10-31 22:16:52,955:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-10-31 22:16:52,955:INFO:Engine successfully changes for model 'ridge' to 'sklearn'.
2023-10-31 22:16:52,969:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-10-31 22:16:53,052:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-10-31 22:16:53,106:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-10-31 22:16:53,107:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-10-31 22:16:53,107:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-10-31 22:16:53,119:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-10-31 22:16:53,189:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-10-31 22:16:53,243:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-10-31 22:16:53,243:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-10-31 22:16:53,244:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-10-31 22:16:53,244:INFO:Engine successfully changes for model 'en' to 'sklearn'.
2023-10-31 22:16:53,324:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-10-31 22:16:53,378:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-10-31 22:16:53,379:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-10-31 22:16:53,379:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-10-31 22:16:53,461:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-10-31 22:16:53,515:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-10-31 22:16:53,516:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-10-31 22:16:53,516:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-10-31 22:16:53,516:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2023-10-31 22:16:53,598:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-10-31 22:16:53,653:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-10-31 22:16:53,653:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-10-31 22:16:53,735:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-10-31 22:16:53,791:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-10-31 22:16:53,791:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-10-31 22:16:53,792:INFO:Engine successfully changes for model 'svm' to 'sklearn'.
2023-10-31 22:16:53,928:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-10-31 22:16:53,928:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-10-31 22:16:54,066:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-10-31 22:16:54,067:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-10-31 22:16:54,085:INFO:Preparing preprocessing pipeline...
2023-10-31 22:16:54,085:INFO:Set up simple imputation.
2023-10-31 22:16:54,091:INFO:Set up encoding of ordinal features.
2023-10-31 22:16:54,094:WARNING:The number of classes passed to feature Point of Contact in the ordinal_features parameter (2) don't match with the number of classes in the data (3).
2023-10-31 22:16:54,095:INFO:Set up encoding of categorical features.
2023-10-31 22:16:54,096:INFO:Set up column name cleaning.
2023-10-31 22:16:54,254:INFO:Finished creating preprocessing pipeline.
2023-10-31 22:16:54,284:INFO:Pipeline: Pipeline(memory=FastMemory(location=C:\Users\CHRIST~1\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['BHK', 'Size', 'Bathroom'],
                                    transformer=SimpleImputer())),
                ('categorical_imputer',
                 TransformerWrapper(include=['Area Type', 'City',
                                             'Furnishing Status',
                                             'Tenant Preferred',
                                             'Point of Contact'],
                                    transformer=SimpleImputer(strategy...
Contact Owner    1
NaN             -1
dtype: int64}]))),
                ('onehot_encoding',
                 TransformerWrapper(include=['Area Type', 'City',
                                             'Furnishing Status',
                                             'Tenant Preferred'],
                                    transformer=OneHotEncoder(cols=['Area Type',
                                                                    'City',
                                                                    'Furnishing '
                                                                    'Status',
                                                                    'Tenant '
                                                                    'Preferred'],
                                                              handle_missing='return_nan',
                                                              use_cat_names=True))),
                ('clean_column_names',
                 TransformerWrapper(transformer=CleanColumnNames()))])
2023-10-31 22:16:54,284:INFO:Creating final display dataframe.
2023-10-31 22:16:54,623:INFO:Setup _display_container:                     Description             Value
0                    Session id               123
1                        Target              Rent
2                   Target type        Regression
3           Original data shape        (4746, 12)
4        Transformed data shape        (4746, 20)
5   Transformed train set shape        (3322, 20)
6    Transformed test set shape        (1424, 20)
7               Ignore features                 3
8              Ordinal features                 1
9              Numeric features                 3
10         Categorical features                 5
11                   Preprocess              True
12              Imputation type            simple
13           Numeric imputation              mean
14       Categorical imputation              mode
15     Maximum one-hot encoding                25
16              Encoding method              None
17               Fold Generator             KFold
18                  Fold Number                10
19                     CPU Jobs                -1
20                      Use GPU             False
21               Log Experiment             False
22              Experiment Name  reg-default-name
23                          USI              ee2c
2023-10-31 22:16:54,777:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-10-31 22:16:54,778:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-10-31 22:16:54,916:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-10-31 22:16:54,916:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-10-31 22:16:54,917:INFO:setup() successfully completed in 3.09s...............
2023-10-31 22:25:02,526:INFO:Initializing compare_models()
2023-10-31 22:25:02,526:INFO:compare_models(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001FEC8CB3700>, include=None, fold=None, round=4, cross_validation=True, sort=R2, n_select=1, budget_time=None, turbo=True, errors=ignore, fit_kwargs=None, groups=None, experiment_custom_tags=None, probability_threshold=None, verbose=True, parallel=None, caller_params={'self': <pycaret.regression.oop.RegressionExperiment object at 0x000001FEC8CB3700>, 'include': None, 'exclude': None, 'fold': None, 'round': 4, 'cross_validation': True, 'sort': 'R2', 'n_select': 1, 'budget_time': None, 'turbo': True, 'errors': 'ignore', 'fit_kwargs': None, 'groups': None, 'experiment_custom_tags': None, 'engine': None, 'verbose': True, 'parallel': None, '__class__': <class 'pycaret.regression.oop.RegressionExperiment'>}, exclude=None)
2023-10-31 22:25:02,526:INFO:Checking exceptions
2023-10-31 22:25:02,530:INFO:Preparing display monitor
2023-10-31 22:25:02,560:INFO:Initializing Linear Regression
2023-10-31 22:25:02,560:INFO:Total runtime is 0.0 minutes
2023-10-31 22:25:02,565:INFO:SubProcess create_model() called ==================================
2023-10-31 22:25:02,565:INFO:Initializing create_model()
2023-10-31 22:25:02,565:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001FEC8CB3700>, estimator=lr, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001FEC90F1940>, model_only=True, return_train_score=False, kwargs={})
2023-10-31 22:25:02,566:INFO:Checking exceptions
2023-10-31 22:25:02,566:INFO:Importing libraries
2023-10-31 22:25:02,566:INFO:Copying training dataset
2023-10-31 22:25:02,571:INFO:Defining folds
2023-10-31 22:25:02,571:INFO:Declaring metric variables
2023-10-31 22:25:02,574:INFO:Importing untrained model
2023-10-31 22:25:02,579:INFO:Linear Regression Imported successfully
2023-10-31 22:25:02,588:INFO:Starting cross validation
2023-10-31 22:25:02,596:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-10-31 22:25:06,865:INFO:Calculating mean and std
2023-10-31 22:25:06,867:INFO:Creating metrics dataframe
2023-10-31 22:25:06,871:INFO:Uploading results into container
2023-10-31 22:25:06,872:INFO:Uploading model into container now
2023-10-31 22:25:06,873:INFO:_master_model_container: 1
2023-10-31 22:25:06,873:INFO:_display_container: 2
2023-10-31 22:25:06,873:INFO:LinearRegression(n_jobs=-1)
2023-10-31 22:25:06,873:INFO:create_model() successfully completed......................................
2023-10-31 22:25:07,034:INFO:SubProcess create_model() end ==================================
2023-10-31 22:25:07,034:INFO:Creating metrics dataframe
2023-10-31 22:25:07,047:INFO:Initializing Lasso Regression
2023-10-31 22:25:07,047:INFO:Total runtime is 0.07477625608444213 minutes
2023-10-31 22:25:07,053:INFO:SubProcess create_model() called ==================================
2023-10-31 22:25:07,054:INFO:Initializing create_model()
2023-10-31 22:25:07,054:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001FEC8CB3700>, estimator=lasso, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001FEC90F1940>, model_only=True, return_train_score=False, kwargs={})
2023-10-31 22:25:07,055:INFO:Checking exceptions
2023-10-31 22:25:07,055:INFO:Importing libraries
2023-10-31 22:25:07,055:INFO:Copying training dataset
2023-10-31 22:25:07,062:INFO:Defining folds
2023-10-31 22:25:07,063:INFO:Declaring metric variables
2023-10-31 22:25:07,068:INFO:Importing untrained model
2023-10-31 22:25:07,074:INFO:Lasso Regression Imported successfully
2023-10-31 22:25:07,087:INFO:Starting cross validation
2023-10-31 22:25:07,090:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-10-31 22:25:10,226:WARNING:d:\trabajo\dmc\202311\pea da\pea_da\lib\site-packages\sklearn\linear_model\_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.759e+11, tolerance: 2.136e+09
  model = cd_fast.enet_coordinate_descent(

2023-10-31 22:25:10,385:INFO:Calculating mean and std
2023-10-31 22:25:10,388:INFO:Creating metrics dataframe
2023-10-31 22:25:10,392:INFO:Uploading results into container
2023-10-31 22:25:10,393:INFO:Uploading model into container now
2023-10-31 22:25:10,393:INFO:_master_model_container: 2
2023-10-31 22:25:10,393:INFO:_display_container: 2
2023-10-31 22:25:10,394:INFO:Lasso(random_state=123)
2023-10-31 22:25:10,394:INFO:create_model() successfully completed......................................
2023-10-31 22:25:10,540:INFO:SubProcess create_model() end ==================================
2023-10-31 22:25:10,540:INFO:Creating metrics dataframe
2023-10-31 22:25:10,552:INFO:Initializing Ridge Regression
2023-10-31 22:25:10,553:INFO:Total runtime is 0.1332171360651652 minutes
2023-10-31 22:25:10,556:INFO:SubProcess create_model() called ==================================
2023-10-31 22:25:10,557:INFO:Initializing create_model()
2023-10-31 22:25:10,557:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001FEC8CB3700>, estimator=ridge, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001FEC90F1940>, model_only=True, return_train_score=False, kwargs={})
2023-10-31 22:25:10,557:INFO:Checking exceptions
2023-10-31 22:25:10,557:INFO:Importing libraries
2023-10-31 22:25:10,557:INFO:Copying training dataset
2023-10-31 22:25:10,564:INFO:Defining folds
2023-10-31 22:25:10,564:INFO:Declaring metric variables
2023-10-31 22:25:10,569:INFO:Importing untrained model
2023-10-31 22:25:10,574:INFO:Ridge Regression Imported successfully
2023-10-31 22:25:10,585:INFO:Starting cross validation
2023-10-31 22:25:10,587:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-10-31 22:25:13,790:INFO:Calculating mean and std
2023-10-31 22:25:13,792:INFO:Creating metrics dataframe
2023-10-31 22:25:13,800:INFO:Uploading results into container
2023-10-31 22:25:13,803:INFO:Uploading model into container now
2023-10-31 22:25:13,804:INFO:_master_model_container: 3
2023-10-31 22:25:13,804:INFO:_display_container: 2
2023-10-31 22:25:13,805:INFO:Ridge(random_state=123)
2023-10-31 22:25:13,805:INFO:create_model() successfully completed......................................
2023-10-31 22:25:13,959:INFO:SubProcess create_model() end ==================================
2023-10-31 22:25:13,959:INFO:Creating metrics dataframe
2023-10-31 22:25:13,969:INFO:Initializing Elastic Net
2023-10-31 22:25:13,969:INFO:Total runtime is 0.190155553817749 minutes
2023-10-31 22:25:13,973:INFO:SubProcess create_model() called ==================================
2023-10-31 22:25:13,973:INFO:Initializing create_model()
2023-10-31 22:25:13,974:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001FEC8CB3700>, estimator=en, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001FEC90F1940>, model_only=True, return_train_score=False, kwargs={})
2023-10-31 22:25:13,974:INFO:Checking exceptions
2023-10-31 22:25:13,974:INFO:Importing libraries
2023-10-31 22:25:13,974:INFO:Copying training dataset
2023-10-31 22:25:13,979:INFO:Defining folds
2023-10-31 22:25:13,979:INFO:Declaring metric variables
2023-10-31 22:25:13,983:INFO:Importing untrained model
2023-10-31 22:25:13,987:INFO:Elastic Net Imported successfully
2023-10-31 22:25:13,996:INFO:Starting cross validation
2023-10-31 22:25:13,998:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-10-31 22:25:16,549:INFO:Calculating mean and std
2023-10-31 22:25:16,551:INFO:Creating metrics dataframe
2023-10-31 22:25:16,555:INFO:Uploading results into container
2023-10-31 22:25:16,556:INFO:Uploading model into container now
2023-10-31 22:25:16,557:INFO:_master_model_container: 4
2023-10-31 22:25:16,557:INFO:_display_container: 2
2023-10-31 22:25:16,557:INFO:ElasticNet(random_state=123)
2023-10-31 22:25:16,557:INFO:create_model() successfully completed......................................
2023-10-31 22:25:16,707:INFO:SubProcess create_model() end ==================================
2023-10-31 22:25:16,707:INFO:Creating metrics dataframe
2023-10-31 22:25:16,717:INFO:Initializing Least Angle Regression
2023-10-31 22:25:16,718:INFO:Total runtime is 0.23596916993459066 minutes
2023-10-31 22:25:16,721:INFO:SubProcess create_model() called ==================================
2023-10-31 22:25:16,721:INFO:Initializing create_model()
2023-10-31 22:25:16,722:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001FEC8CB3700>, estimator=lar, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001FEC90F1940>, model_only=True, return_train_score=False, kwargs={})
2023-10-31 22:25:16,722:INFO:Checking exceptions
2023-10-31 22:25:16,722:INFO:Importing libraries
2023-10-31 22:25:16,722:INFO:Copying training dataset
2023-10-31 22:25:16,730:INFO:Defining folds
2023-10-31 22:25:16,730:INFO:Declaring metric variables
2023-10-31 22:25:16,734:INFO:Importing untrained model
2023-10-31 22:25:16,739:INFO:Least Angle Regression Imported successfully
2023-10-31 22:25:16,750:INFO:Starting cross validation
2023-10-31 22:25:16,752:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-10-31 22:25:16,988:INFO:Calculating mean and std
2023-10-31 22:25:16,990:INFO:Creating metrics dataframe
2023-10-31 22:25:16,993:INFO:Uploading results into container
2023-10-31 22:25:16,994:INFO:Uploading model into container now
2023-10-31 22:25:16,994:INFO:_master_model_container: 5
2023-10-31 22:25:16,994:INFO:_display_container: 2
2023-10-31 22:25:16,994:INFO:Lars(random_state=123)
2023-10-31 22:25:16,995:INFO:create_model() successfully completed......................................
2023-10-31 22:25:17,138:INFO:SubProcess create_model() end ==================================
2023-10-31 22:25:17,138:INFO:Creating metrics dataframe
2023-10-31 22:25:17,149:INFO:Initializing Lasso Least Angle Regression
2023-10-31 22:25:17,150:INFO:Total runtime is 0.2431706190109253 minutes
2023-10-31 22:25:17,153:INFO:SubProcess create_model() called ==================================
2023-10-31 22:25:17,154:INFO:Initializing create_model()
2023-10-31 22:25:17,154:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001FEC8CB3700>, estimator=llar, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001FEC90F1940>, model_only=True, return_train_score=False, kwargs={})
2023-10-31 22:25:17,154:INFO:Checking exceptions
2023-10-31 22:25:17,154:INFO:Importing libraries
2023-10-31 22:25:17,154:INFO:Copying training dataset
2023-10-31 22:25:17,160:INFO:Defining folds
2023-10-31 22:25:17,160:INFO:Declaring metric variables
2023-10-31 22:25:17,164:INFO:Importing untrained model
2023-10-31 22:25:17,169:INFO:Lasso Least Angle Regression Imported successfully
2023-10-31 22:25:17,179:INFO:Starting cross validation
2023-10-31 22:25:17,180:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-10-31 22:25:17,426:INFO:Calculating mean and std
2023-10-31 22:25:17,428:INFO:Creating metrics dataframe
2023-10-31 22:25:17,431:INFO:Uploading results into container
2023-10-31 22:25:17,432:INFO:Uploading model into container now
2023-10-31 22:25:17,433:INFO:_master_model_container: 6
2023-10-31 22:25:17,433:INFO:_display_container: 2
2023-10-31 22:25:17,433:INFO:LassoLars(random_state=123)
2023-10-31 22:25:17,434:INFO:create_model() successfully completed......................................
2023-10-31 22:25:17,581:INFO:SubProcess create_model() end ==================================
2023-10-31 22:25:17,581:INFO:Creating metrics dataframe
2023-10-31 22:25:17,594:INFO:Initializing Orthogonal Matching Pursuit
2023-10-31 22:25:17,595:INFO:Total runtime is 0.2505873163541158 minutes
2023-10-31 22:25:17,599:INFO:SubProcess create_model() called ==================================
2023-10-31 22:25:17,600:INFO:Initializing create_model()
2023-10-31 22:25:17,600:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001FEC8CB3700>, estimator=omp, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001FEC90F1940>, model_only=True, return_train_score=False, kwargs={})
2023-10-31 22:25:17,600:INFO:Checking exceptions
2023-10-31 22:25:17,600:INFO:Importing libraries
2023-10-31 22:25:17,600:INFO:Copying training dataset
2023-10-31 22:25:17,607:INFO:Defining folds
2023-10-31 22:25:17,608:INFO:Declaring metric variables
2023-10-31 22:25:17,613:INFO:Importing untrained model
2023-10-31 22:25:17,618:INFO:Orthogonal Matching Pursuit Imported successfully
2023-10-31 22:25:17,627:INFO:Starting cross validation
2023-10-31 22:25:17,629:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-10-31 22:25:17,913:INFO:Calculating mean and std
2023-10-31 22:25:17,915:INFO:Creating metrics dataframe
2023-10-31 22:25:17,920:INFO:Uploading results into container
2023-10-31 22:25:17,921:INFO:Uploading model into container now
2023-10-31 22:25:17,922:INFO:_master_model_container: 7
2023-10-31 22:25:17,922:INFO:_display_container: 2
2023-10-31 22:25:17,923:INFO:OrthogonalMatchingPursuit()
2023-10-31 22:25:17,923:INFO:create_model() successfully completed......................................
2023-10-31 22:25:18,092:INFO:SubProcess create_model() end ==================================
2023-10-31 22:25:18,092:INFO:Creating metrics dataframe
2023-10-31 22:25:18,114:INFO:Initializing Bayesian Ridge
2023-10-31 22:25:18,114:INFO:Total runtime is 0.25923738479614256 minutes
2023-10-31 22:25:18,120:INFO:SubProcess create_model() called ==================================
2023-10-31 22:25:18,121:INFO:Initializing create_model()
2023-10-31 22:25:18,122:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001FEC8CB3700>, estimator=br, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001FEC90F1940>, model_only=True, return_train_score=False, kwargs={})
2023-10-31 22:25:18,122:INFO:Checking exceptions
2023-10-31 22:25:18,122:INFO:Importing libraries
2023-10-31 22:25:18,122:INFO:Copying training dataset
2023-10-31 22:25:18,131:INFO:Defining folds
2023-10-31 22:25:18,131:INFO:Declaring metric variables
2023-10-31 22:25:18,138:INFO:Importing untrained model
2023-10-31 22:25:18,144:INFO:Bayesian Ridge Imported successfully
2023-10-31 22:25:18,159:INFO:Starting cross validation
2023-10-31 22:25:18,162:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-10-31 22:25:18,472:INFO:Calculating mean and std
2023-10-31 22:25:18,474:INFO:Creating metrics dataframe
2023-10-31 22:25:18,479:INFO:Uploading results into container
2023-10-31 22:25:18,481:INFO:Uploading model into container now
2023-10-31 22:25:18,481:INFO:_master_model_container: 8
2023-10-31 22:25:18,481:INFO:_display_container: 2
2023-10-31 22:25:18,482:INFO:BayesianRidge()
2023-10-31 22:25:18,482:INFO:create_model() successfully completed......................................
2023-10-31 22:25:18,641:INFO:SubProcess create_model() end ==================================
2023-10-31 22:25:18,641:INFO:Creating metrics dataframe
2023-10-31 22:25:18,655:INFO:Initializing Passive Aggressive Regressor
2023-10-31 22:25:18,655:INFO:Total runtime is 0.26825397411982216 minutes
2023-10-31 22:25:18,659:INFO:SubProcess create_model() called ==================================
2023-10-31 22:25:18,660:INFO:Initializing create_model()
2023-10-31 22:25:18,660:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001FEC8CB3700>, estimator=par, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001FEC90F1940>, model_only=True, return_train_score=False, kwargs={})
2023-10-31 22:25:18,660:INFO:Checking exceptions
2023-10-31 22:25:18,660:INFO:Importing libraries
2023-10-31 22:25:18,660:INFO:Copying training dataset
2023-10-31 22:25:18,666:INFO:Defining folds
2023-10-31 22:25:18,667:INFO:Declaring metric variables
2023-10-31 22:25:18,673:INFO:Importing untrained model
2023-10-31 22:25:18,678:INFO:Passive Aggressive Regressor Imported successfully
2023-10-31 22:25:18,688:INFO:Starting cross validation
2023-10-31 22:25:18,690:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-10-31 22:25:18,940:INFO:Calculating mean and std
2023-10-31 22:25:18,942:INFO:Creating metrics dataframe
2023-10-31 22:25:18,945:INFO:Uploading results into container
2023-10-31 22:25:18,946:INFO:Uploading model into container now
2023-10-31 22:25:18,947:INFO:_master_model_container: 9
2023-10-31 22:25:18,947:INFO:_display_container: 2
2023-10-31 22:25:18,947:INFO:PassiveAggressiveRegressor(random_state=123)
2023-10-31 22:25:18,948:INFO:create_model() successfully completed......................................
2023-10-31 22:25:19,095:INFO:SubProcess create_model() end ==================================
2023-10-31 22:25:19,095:INFO:Creating metrics dataframe
2023-10-31 22:25:19,111:INFO:Initializing Huber Regressor
2023-10-31 22:25:19,111:INFO:Total runtime is 0.2758540312449137 minutes
2023-10-31 22:25:19,116:INFO:SubProcess create_model() called ==================================
2023-10-31 22:25:19,117:INFO:Initializing create_model()
2023-10-31 22:25:19,117:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001FEC8CB3700>, estimator=huber, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001FEC90F1940>, model_only=True, return_train_score=False, kwargs={})
2023-10-31 22:25:19,117:INFO:Checking exceptions
2023-10-31 22:25:19,117:INFO:Importing libraries
2023-10-31 22:25:19,117:INFO:Copying training dataset
2023-10-31 22:25:19,124:INFO:Defining folds
2023-10-31 22:25:19,124:INFO:Declaring metric variables
2023-10-31 22:25:19,129:INFO:Importing untrained model
2023-10-31 22:25:19,134:INFO:Huber Regressor Imported successfully
2023-10-31 22:25:19,142:INFO:Starting cross validation
2023-10-31 22:25:19,144:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-10-31 22:25:19,367:WARNING:d:\trabajo\dmc\202311\pea da\pea_da\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-10-31 22:25:19,384:WARNING:d:\trabajo\dmc\202311\pea da\pea_da\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-10-31 22:25:19,391:WARNING:d:\trabajo\dmc\202311\pea da\pea_da\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-10-31 22:25:19,391:WARNING:d:\trabajo\dmc\202311\pea da\pea_da\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-10-31 22:25:19,398:WARNING:d:\trabajo\dmc\202311\pea da\pea_da\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-10-31 22:25:19,406:WARNING:d:\trabajo\dmc\202311\pea da\pea_da\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-10-31 22:25:19,409:WARNING:d:\trabajo\dmc\202311\pea da\pea_da\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-10-31 22:25:19,410:WARNING:d:\trabajo\dmc\202311\pea da\pea_da\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-10-31 22:25:19,430:WARNING:d:\trabajo\dmc\202311\pea da\pea_da\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-10-31 22:25:19,486:INFO:Calculating mean and std
2023-10-31 22:25:19,488:INFO:Creating metrics dataframe
2023-10-31 22:25:19,492:INFO:Uploading results into container
2023-10-31 22:25:19,493:INFO:Uploading model into container now
2023-10-31 22:25:19,494:INFO:_master_model_container: 10
2023-10-31 22:25:19,494:INFO:_display_container: 2
2023-10-31 22:25:19,494:INFO:HuberRegressor()
2023-10-31 22:25:19,494:INFO:create_model() successfully completed......................................
2023-10-31 22:25:19,665:INFO:SubProcess create_model() end ==================================
2023-10-31 22:25:19,665:INFO:Creating metrics dataframe
2023-10-31 22:25:19,679:INFO:Initializing K Neighbors Regressor
2023-10-31 22:25:19,679:INFO:Total runtime is 0.2853207151095072 minutes
2023-10-31 22:25:19,684:INFO:SubProcess create_model() called ==================================
2023-10-31 22:25:19,685:INFO:Initializing create_model()
2023-10-31 22:25:19,685:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001FEC8CB3700>, estimator=knn, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001FEC90F1940>, model_only=True, return_train_score=False, kwargs={})
2023-10-31 22:25:19,685:INFO:Checking exceptions
2023-10-31 22:25:19,685:INFO:Importing libraries
2023-10-31 22:25:19,685:INFO:Copying training dataset
2023-10-31 22:25:19,693:INFO:Defining folds
2023-10-31 22:25:19,693:INFO:Declaring metric variables
2023-10-31 22:25:19,699:INFO:Importing untrained model
2023-10-31 22:25:19,704:INFO:K Neighbors Regressor Imported successfully
2023-10-31 22:25:19,712:INFO:Starting cross validation
2023-10-31 22:25:19,714:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-10-31 22:25:20,116:INFO:Calculating mean and std
2023-10-31 22:25:20,118:INFO:Creating metrics dataframe
2023-10-31 22:25:20,122:INFO:Uploading results into container
2023-10-31 22:25:20,123:INFO:Uploading model into container now
2023-10-31 22:25:20,124:INFO:_master_model_container: 11
2023-10-31 22:25:20,124:INFO:_display_container: 2
2023-10-31 22:25:20,124:INFO:KNeighborsRegressor(n_jobs=-1)
2023-10-31 22:25:20,124:INFO:create_model() successfully completed......................................
2023-10-31 22:25:20,271:INFO:SubProcess create_model() end ==================================
2023-10-31 22:25:20,271:INFO:Creating metrics dataframe
2023-10-31 22:25:20,285:INFO:Initializing Decision Tree Regressor
2023-10-31 22:25:20,285:INFO:Total runtime is 0.2954197605450947 minutes
2023-10-31 22:25:20,290:INFO:SubProcess create_model() called ==================================
2023-10-31 22:25:20,290:INFO:Initializing create_model()
2023-10-31 22:25:20,291:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001FEC8CB3700>, estimator=dt, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001FEC90F1940>, model_only=True, return_train_score=False, kwargs={})
2023-10-31 22:25:20,291:INFO:Checking exceptions
2023-10-31 22:25:20,291:INFO:Importing libraries
2023-10-31 22:25:20,291:INFO:Copying training dataset
2023-10-31 22:25:20,297:INFO:Defining folds
2023-10-31 22:25:20,298:INFO:Declaring metric variables
2023-10-31 22:25:20,303:INFO:Importing untrained model
2023-10-31 22:25:20,308:INFO:Decision Tree Regressor Imported successfully
2023-10-31 22:25:20,316:INFO:Starting cross validation
2023-10-31 22:25:20,318:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-10-31 22:25:20,615:INFO:Calculating mean and std
2023-10-31 22:25:20,617:INFO:Creating metrics dataframe
2023-10-31 22:25:20,621:INFO:Uploading results into container
2023-10-31 22:25:20,622:INFO:Uploading model into container now
2023-10-31 22:25:20,623:INFO:_master_model_container: 12
2023-10-31 22:25:20,623:INFO:_display_container: 2
2023-10-31 22:25:20,624:INFO:DecisionTreeRegressor(random_state=123)
2023-10-31 22:25:20,624:INFO:create_model() successfully completed......................................
2023-10-31 22:25:20,785:INFO:SubProcess create_model() end ==================================
2023-10-31 22:25:20,785:INFO:Creating metrics dataframe
2023-10-31 22:25:20,798:INFO:Initializing Random Forest Regressor
2023-10-31 22:25:20,798:INFO:Total runtime is 0.30396885077158603 minutes
2023-10-31 22:25:20,801:INFO:SubProcess create_model() called ==================================
2023-10-31 22:25:20,802:INFO:Initializing create_model()
2023-10-31 22:25:20,802:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001FEC8CB3700>, estimator=rf, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001FEC90F1940>, model_only=True, return_train_score=False, kwargs={})
2023-10-31 22:25:20,802:INFO:Checking exceptions
2023-10-31 22:25:20,802:INFO:Importing libraries
2023-10-31 22:25:20,802:INFO:Copying training dataset
2023-10-31 22:25:20,809:INFO:Defining folds
2023-10-31 22:25:20,809:INFO:Declaring metric variables
2023-10-31 22:25:20,815:INFO:Importing untrained model
2023-10-31 22:25:20,819:INFO:Random Forest Regressor Imported successfully
2023-10-31 22:25:20,830:INFO:Starting cross validation
2023-10-31 22:25:20,832:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-10-31 22:25:21,731:INFO:Calculating mean and std
2023-10-31 22:25:21,733:INFO:Creating metrics dataframe
2023-10-31 22:25:21,737:INFO:Uploading results into container
2023-10-31 22:25:21,738:INFO:Uploading model into container now
2023-10-31 22:25:21,738:INFO:_master_model_container: 13
2023-10-31 22:25:21,739:INFO:_display_container: 2
2023-10-31 22:25:21,739:INFO:RandomForestRegressor(n_jobs=-1, random_state=123)
2023-10-31 22:25:21,739:INFO:create_model() successfully completed......................................
2023-10-31 22:25:21,886:INFO:SubProcess create_model() end ==================================
2023-10-31 22:25:21,886:INFO:Creating metrics dataframe
2023-10-31 22:25:21,900:INFO:Initializing Extra Trees Regressor
2023-10-31 22:25:21,900:INFO:Total runtime is 0.32233672936757396 minutes
2023-10-31 22:25:21,905:INFO:SubProcess create_model() called ==================================
2023-10-31 22:25:21,905:INFO:Initializing create_model()
2023-10-31 22:25:21,905:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001FEC8CB3700>, estimator=et, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001FEC90F1940>, model_only=True, return_train_score=False, kwargs={})
2023-10-31 22:25:21,905:INFO:Checking exceptions
2023-10-31 22:25:21,906:INFO:Importing libraries
2023-10-31 22:25:21,906:INFO:Copying training dataset
2023-10-31 22:25:21,912:INFO:Defining folds
2023-10-31 22:25:21,912:INFO:Declaring metric variables
2023-10-31 22:25:21,917:INFO:Importing untrained model
2023-10-31 22:25:21,921:INFO:Extra Trees Regressor Imported successfully
2023-10-31 22:25:21,930:INFO:Starting cross validation
2023-10-31 22:25:21,932:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-10-31 22:25:22,794:INFO:Calculating mean and std
2023-10-31 22:25:22,797:INFO:Creating metrics dataframe
2023-10-31 22:25:22,801:INFO:Uploading results into container
2023-10-31 22:25:22,803:INFO:Uploading model into container now
2023-10-31 22:25:22,804:INFO:_master_model_container: 14
2023-10-31 22:25:22,804:INFO:_display_container: 2
2023-10-31 22:25:22,804:INFO:ExtraTreesRegressor(n_jobs=-1, random_state=123)
2023-10-31 22:25:22,805:INFO:create_model() successfully completed......................................
2023-10-31 22:25:22,966:INFO:SubProcess create_model() end ==================================
2023-10-31 22:25:22,966:INFO:Creating metrics dataframe
2023-10-31 22:25:22,982:INFO:Initializing AdaBoost Regressor
2023-10-31 22:25:22,982:INFO:Total runtime is 0.3403700828552245 minutes
2023-10-31 22:25:22,986:INFO:SubProcess create_model() called ==================================
2023-10-31 22:25:22,987:INFO:Initializing create_model()
2023-10-31 22:25:22,988:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001FEC8CB3700>, estimator=ada, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001FEC90F1940>, model_only=True, return_train_score=False, kwargs={})
2023-10-31 22:25:22,988:INFO:Checking exceptions
2023-10-31 22:25:22,988:INFO:Importing libraries
2023-10-31 22:25:22,988:INFO:Copying training dataset
2023-10-31 22:25:22,995:INFO:Defining folds
2023-10-31 22:25:22,995:INFO:Declaring metric variables
2023-10-31 22:25:23,001:INFO:Importing untrained model
2023-10-31 22:25:23,007:INFO:AdaBoost Regressor Imported successfully
2023-10-31 22:25:23,017:INFO:Starting cross validation
2023-10-31 22:25:23,020:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-10-31 22:25:23,533:INFO:Calculating mean and std
2023-10-31 22:25:23,535:INFO:Creating metrics dataframe
2023-10-31 22:25:23,539:INFO:Uploading results into container
2023-10-31 22:25:23,540:INFO:Uploading model into container now
2023-10-31 22:25:23,541:INFO:_master_model_container: 15
2023-10-31 22:25:23,541:INFO:_display_container: 2
2023-10-31 22:25:23,541:INFO:AdaBoostRegressor(random_state=123)
2023-10-31 22:25:23,542:INFO:create_model() successfully completed......................................
2023-10-31 22:25:23,684:INFO:SubProcess create_model() end ==================================
2023-10-31 22:25:23,684:INFO:Creating metrics dataframe
2023-10-31 22:25:23,698:INFO:Initializing Gradient Boosting Regressor
2023-10-31 22:25:23,698:INFO:Total runtime is 0.35230348507563264 minutes
2023-10-31 22:25:23,702:INFO:SubProcess create_model() called ==================================
2023-10-31 22:25:23,702:INFO:Initializing create_model()
2023-10-31 22:25:23,702:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001FEC8CB3700>, estimator=gbr, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001FEC90F1940>, model_only=True, return_train_score=False, kwargs={})
2023-10-31 22:25:23,702:INFO:Checking exceptions
2023-10-31 22:25:23,702:INFO:Importing libraries
2023-10-31 22:25:23,703:INFO:Copying training dataset
2023-10-31 22:25:23,709:INFO:Defining folds
2023-10-31 22:25:23,709:INFO:Declaring metric variables
2023-10-31 22:25:23,714:INFO:Importing untrained model
2023-10-31 22:25:23,719:INFO:Gradient Boosting Regressor Imported successfully
2023-10-31 22:25:23,727:INFO:Starting cross validation
2023-10-31 22:25:23,729:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-10-31 22:25:24,189:INFO:Calculating mean and std
2023-10-31 22:25:24,191:INFO:Creating metrics dataframe
2023-10-31 22:25:24,194:INFO:Uploading results into container
2023-10-31 22:25:24,195:INFO:Uploading model into container now
2023-10-31 22:25:24,196:INFO:_master_model_container: 16
2023-10-31 22:25:24,196:INFO:_display_container: 2
2023-10-31 22:25:24,196:INFO:GradientBoostingRegressor(random_state=123)
2023-10-31 22:25:24,196:INFO:create_model() successfully completed......................................
2023-10-31 22:25:24,338:INFO:SubProcess create_model() end ==================================
2023-10-31 22:25:24,338:INFO:Creating metrics dataframe
2023-10-31 22:25:24,352:INFO:Initializing Light Gradient Boosting Machine
2023-10-31 22:25:24,353:INFO:Total runtime is 0.3632094701131184 minutes
2023-10-31 22:25:24,358:INFO:SubProcess create_model() called ==================================
2023-10-31 22:25:24,358:INFO:Initializing create_model()
2023-10-31 22:25:24,359:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001FEC8CB3700>, estimator=lightgbm, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001FEC90F1940>, model_only=True, return_train_score=False, kwargs={})
2023-10-31 22:25:24,359:INFO:Checking exceptions
2023-10-31 22:25:24,359:INFO:Importing libraries
2023-10-31 22:25:24,359:INFO:Copying training dataset
2023-10-31 22:25:24,368:INFO:Defining folds
2023-10-31 22:25:24,368:INFO:Declaring metric variables
2023-10-31 22:25:24,374:INFO:Importing untrained model
2023-10-31 22:25:24,381:INFO:Light Gradient Boosting Machine Imported successfully
2023-10-31 22:25:24,389:INFO:Starting cross validation
2023-10-31 22:25:24,391:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-10-31 22:25:25,581:INFO:Calculating mean and std
2023-10-31 22:25:25,583:INFO:Creating metrics dataframe
2023-10-31 22:25:25,588:INFO:Uploading results into container
2023-10-31 22:25:25,590:INFO:Uploading model into container now
2023-10-31 22:25:25,590:INFO:_master_model_container: 17
2023-10-31 22:25:25,590:INFO:_display_container: 2
2023-10-31 22:25:25,591:INFO:LGBMRegressor(n_jobs=-1, random_state=123)
2023-10-31 22:25:25,591:INFO:create_model() successfully completed......................................
2023-10-31 22:25:25,761:INFO:SubProcess create_model() end ==================================
2023-10-31 22:25:25,761:INFO:Creating metrics dataframe
2023-10-31 22:25:25,776:INFO:Initializing Dummy Regressor
2023-10-31 22:25:25,777:INFO:Total runtime is 0.38695470094680773 minutes
2023-10-31 22:25:25,781:INFO:SubProcess create_model() called ==================================
2023-10-31 22:25:25,781:INFO:Initializing create_model()
2023-10-31 22:25:25,781:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001FEC8CB3700>, estimator=dummy, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001FEC90F1940>, model_only=True, return_train_score=False, kwargs={})
2023-10-31 22:25:25,782:INFO:Checking exceptions
2023-10-31 22:25:25,782:INFO:Importing libraries
2023-10-31 22:25:25,782:INFO:Copying training dataset
2023-10-31 22:25:25,789:INFO:Defining folds
2023-10-31 22:25:25,789:INFO:Declaring metric variables
2023-10-31 22:25:25,793:INFO:Importing untrained model
2023-10-31 22:25:25,798:INFO:Dummy Regressor Imported successfully
2023-10-31 22:25:25,805:INFO:Starting cross validation
2023-10-31 22:25:25,807:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-10-31 22:25:26,079:INFO:Calculating mean and std
2023-10-31 22:25:26,081:INFO:Creating metrics dataframe
2023-10-31 22:25:26,085:INFO:Uploading results into container
2023-10-31 22:25:26,086:INFO:Uploading model into container now
2023-10-31 22:25:26,087:INFO:_master_model_container: 18
2023-10-31 22:25:26,087:INFO:_display_container: 2
2023-10-31 22:25:26,087:INFO:DummyRegressor()
2023-10-31 22:25:26,088:INFO:create_model() successfully completed......................................
2023-10-31 22:25:26,236:INFO:SubProcess create_model() end ==================================
2023-10-31 22:25:26,236:INFO:Creating metrics dataframe
2023-10-31 22:25:26,264:INFO:Initializing create_model()
2023-10-31 22:25:26,264:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001FEC8CB3700>, estimator=LGBMRegressor(n_jobs=-1, random_state=123), fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, kwargs={})
2023-10-31 22:25:26,264:INFO:Checking exceptions
2023-10-31 22:25:26,266:INFO:Importing libraries
2023-10-31 22:25:26,266:INFO:Copying training dataset
2023-10-31 22:25:26,271:INFO:Defining folds
2023-10-31 22:25:26,272:INFO:Declaring metric variables
2023-10-31 22:25:26,272:INFO:Importing untrained model
2023-10-31 22:25:26,272:INFO:Declaring custom model
2023-10-31 22:25:26,273:INFO:Light Gradient Boosting Machine Imported successfully
2023-10-31 22:25:26,274:INFO:Cross validation set to False
2023-10-31 22:25:26,274:INFO:Fitting Model
2023-10-31 22:25:26,372:INFO:[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines
2023-10-31 22:25:26,373:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000424 seconds.
2023-10-31 22:25:26,374:INFO:You can set `force_row_wise=true` to remove the overhead.
2023-10-31 22:25:26,374:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2023-10-31 22:25:26,374:INFO:[LightGBM] [Info] Total Bins 282
2023-10-31 22:25:26,374:INFO:[LightGBM] [Info] Number of data points in the train set: 3322, number of used features: 18
2023-10-31 22:25:26,374:INFO:[LightGBM] [Info] Start training from score 34575.285370
2023-10-31 22:25:26,574:INFO:LGBMRegressor(n_jobs=-1, random_state=123)
2023-10-31 22:25:26,575:INFO:create_model() successfully completed......................................
2023-10-31 22:25:26,773:INFO:_master_model_container: 18
2023-10-31 22:25:26,773:INFO:_display_container: 2
2023-10-31 22:25:26,774:INFO:LGBMRegressor(n_jobs=-1, random_state=123)
2023-10-31 22:25:26,774:INFO:compare_models() successfully completed......................................
2023-10-31 22:29:06,697:INFO:Initializing create_model()
2023-10-31 22:29:06,697:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001FEC8CB3700>, estimator=lightgbm, fold=None, round=4, cross_validation=True, predict=True, fit_kwargs=None, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=True, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, kwargs={})
2023-10-31 22:29:06,697:INFO:Checking exceptions
2023-10-31 22:29:06,712:INFO:Importing libraries
2023-10-31 22:29:06,712:INFO:Copying training dataset
2023-10-31 22:29:06,718:INFO:Defining folds
2023-10-31 22:29:06,718:INFO:Declaring metric variables
2023-10-31 22:29:06,722:INFO:Importing untrained model
2023-10-31 22:29:06,727:INFO:Light Gradient Boosting Machine Imported successfully
2023-10-31 22:29:06,736:INFO:Starting cross validation
2023-10-31 22:29:06,738:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-10-31 22:29:07,631:INFO:Calculating mean and std
2023-10-31 22:29:07,632:INFO:Creating metrics dataframe
2023-10-31 22:29:07,638:INFO:Finalizing model
2023-10-31 22:29:07,743:INFO:[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines
2023-10-31 22:29:07,744:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000405 seconds.
2023-10-31 22:29:07,744:INFO:You can set `force_row_wise=true` to remove the overhead.
2023-10-31 22:29:07,745:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2023-10-31 22:29:07,745:INFO:[LightGBM] [Info] Total Bins 282
2023-10-31 22:29:07,745:INFO:[LightGBM] [Info] Number of data points in the train set: 3322, number of used features: 18
2023-10-31 22:29:07,746:INFO:[LightGBM] [Info] Start training from score 34575.285370
2023-10-31 22:29:07,984:INFO:Uploading results into container
2023-10-31 22:29:07,985:INFO:Uploading model into container now
2023-10-31 22:29:07,996:INFO:_master_model_container: 19
2023-10-31 22:29:07,996:INFO:_display_container: 3
2023-10-31 22:29:07,997:INFO:LGBMRegressor(n_jobs=-1, random_state=123)
2023-10-31 22:29:07,997:INFO:create_model() successfully completed......................................
2023-10-31 22:31:43,117:INFO:Initializing tune_model()
2023-10-31 22:31:43,118:INFO:tune_model(estimator=LGBMRegressor(n_jobs=-1, random_state=123), fold=None, round=4, n_iter=20, custom_grid=None, optimize=R2, custom_scorer=None, search_library=scikit-learn, search_algorithm=None, early_stopping=False, early_stopping_max_iters=10, choose_better=True, fit_kwargs=None, groups=None, return_tuner=False, verbose=True, tuner_verbose=True, return_train_score=False, kwargs={}, self=<pycaret.regression.oop.RegressionExperiment object at 0x000001FEC8CB3700>)
2023-10-31 22:31:43,118:INFO:Checking exceptions
2023-10-31 22:31:43,144:INFO:Copying training dataset
2023-10-31 22:31:43,149:INFO:Checking base model
2023-10-31 22:31:43,149:INFO:Base model : Light Gradient Boosting Machine
2023-10-31 22:31:43,153:INFO:Declaring metric variables
2023-10-31 22:31:43,157:INFO:Defining Hyperparameters
2023-10-31 22:31:43,310:INFO:Tuning with n_jobs=-1
2023-10-31 22:31:43,311:INFO:Initializing RandomizedSearchCV
2023-10-31 22:32:07,769:INFO:best_params: {'actual_estimator__reg_lambda': 0.05, 'actual_estimator__reg_alpha': 0.0001, 'actual_estimator__num_leaves': 70, 'actual_estimator__n_estimators': 90, 'actual_estimator__min_split_gain': 0.8, 'actual_estimator__min_child_samples': 61, 'actual_estimator__learning_rate': 0.15, 'actual_estimator__feature_fraction': 1.0, 'actual_estimator__bagging_freq': 2, 'actual_estimator__bagging_fraction': 0.6}
2023-10-31 22:32:07,770:INFO:Hyperparameter search completed
2023-10-31 22:32:07,771:INFO:SubProcess create_model() called ==================================
2023-10-31 22:32:07,771:INFO:Initializing create_model()
2023-10-31 22:32:07,771:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001FEC8CB3700>, estimator=LGBMRegressor(n_jobs=-1, random_state=123), fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001FE942023D0>, model_only=True, return_train_score=False, kwargs={'reg_lambda': 0.05, 'reg_alpha': 0.0001, 'num_leaves': 70, 'n_estimators': 90, 'min_split_gain': 0.8, 'min_child_samples': 61, 'learning_rate': 0.15, 'feature_fraction': 1.0, 'bagging_freq': 2, 'bagging_fraction': 0.6})
2023-10-31 22:32:07,771:INFO:Checking exceptions
2023-10-31 22:32:07,772:INFO:Importing libraries
2023-10-31 22:32:07,772:INFO:Copying training dataset
2023-10-31 22:32:07,777:INFO:Defining folds
2023-10-31 22:32:07,778:INFO:Declaring metric variables
2023-10-31 22:32:07,782:INFO:Importing untrained model
2023-10-31 22:32:07,782:INFO:Declaring custom model
2023-10-31 22:32:07,787:INFO:Light Gradient Boosting Machine Imported successfully
2023-10-31 22:32:07,793:INFO:Starting cross validation
2023-10-31 22:32:07,795:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-10-31 22:32:08,654:INFO:Calculating mean and std
2023-10-31 22:32:08,657:INFO:Creating metrics dataframe
2023-10-31 22:32:08,665:INFO:Finalizing model
2023-10-31 22:32:08,779:INFO:[LightGBM] [Warning] feature_fraction is set=1.0, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1.0
2023-10-31 22:32:08,779:INFO:[LightGBM] [Warning] bagging_fraction is set=0.6, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6
2023-10-31 22:32:08,779:INFO:[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=0 will be ignored. Current value: bagging_freq=2
2023-10-31 22:32:08,782:INFO:[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines
2023-10-31 22:32:08,783:INFO:[LightGBM] [Warning] feature_fraction is set=1.0, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1.0
2023-10-31 22:32:08,783:INFO:[LightGBM] [Warning] bagging_fraction is set=0.6, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6
2023-10-31 22:32:08,783:INFO:[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=0 will be ignored. Current value: bagging_freq=2
2023-10-31 22:32:08,784:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000991 seconds.
2023-10-31 22:32:08,784:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-10-31 22:32:08,784:INFO:[LightGBM] [Info] Total Bins 282
2023-10-31 22:32:08,785:INFO:[LightGBM] [Info] Number of data points in the train set: 3322, number of used features: 18
2023-10-31 22:32:08,785:INFO:[LightGBM] [Info] Start training from score 34575.285370
2023-10-31 22:32:08,787:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-10-31 22:32:08,790:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-10-31 22:32:08,792:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-10-31 22:32:08,794:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-10-31 22:32:08,797:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-10-31 22:32:08,799:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-10-31 22:32:08,802:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-10-31 22:32:08,805:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-10-31 22:32:08,807:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-10-31 22:32:08,809:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-10-31 22:32:08,812:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-10-31 22:32:08,813:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-10-31 22:32:08,815:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-10-31 22:32:08,817:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-10-31 22:32:08,819:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-10-31 22:32:08,820:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-10-31 22:32:08,823:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-10-31 22:32:08,824:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-10-31 22:32:08,827:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-10-31 22:32:08,829:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-10-31 22:32:08,832:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-10-31 22:32:08,836:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-10-31 22:32:08,838:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-10-31 22:32:08,840:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-10-31 22:32:08,843:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-10-31 22:32:08,845:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-10-31 22:32:08,847:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-10-31 22:32:08,849:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-10-31 22:32:08,851:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-10-31 22:32:08,852:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-10-31 22:32:08,854:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-10-31 22:32:08,856:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-10-31 22:32:08,858:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-10-31 22:32:08,859:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-10-31 22:32:08,862:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-10-31 22:32:08,863:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-10-31 22:32:08,865:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-10-31 22:32:08,867:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-10-31 22:32:08,869:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-10-31 22:32:08,871:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-10-31 22:32:08,874:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-10-31 22:32:08,876:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-10-31 22:32:08,878:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-10-31 22:32:08,880:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-10-31 22:32:08,882:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-10-31 22:32:08,884:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-10-31 22:32:08,886:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-10-31 22:32:08,888:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-10-31 22:32:08,892:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-10-31 22:32:08,894:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-10-31 22:32:08,899:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-10-31 22:32:08,901:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-10-31 22:32:08,903:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-10-31 22:32:08,905:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-10-31 22:32:08,907:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-10-31 22:32:08,909:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-10-31 22:32:08,910:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-10-31 22:32:08,912:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-10-31 22:32:08,914:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-10-31 22:32:08,915:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-10-31 22:32:08,917:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-10-31 22:32:08,919:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-10-31 22:32:08,921:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-10-31 22:32:08,922:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-10-31 22:32:08,925:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-10-31 22:32:08,926:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-10-31 22:32:08,928:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-10-31 22:32:08,930:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-10-31 22:32:08,932:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-10-31 22:32:08,933:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-10-31 22:32:08,935:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-10-31 22:32:08,937:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-10-31 22:32:08,939:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-10-31 22:32:08,941:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-10-31 22:32:08,943:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-10-31 22:32:08,945:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-10-31 22:32:08,947:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-10-31 22:32:08,949:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-10-31 22:32:08,951:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-10-31 22:32:08,953:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-10-31 22:32:08,956:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-10-31 22:32:08,958:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-10-31 22:32:08,962:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-10-31 22:32:08,963:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-10-31 22:32:08,965:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-10-31 22:32:08,967:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-10-31 22:32:08,969:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-10-31 22:32:08,970:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-10-31 22:32:08,972:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-10-31 22:32:08,973:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-10-31 22:32:08,992:INFO:Uploading results into container
2023-10-31 22:32:08,993:INFO:Uploading model into container now
2023-10-31 22:32:08,993:INFO:_master_model_container: 20
2023-10-31 22:32:08,994:INFO:_display_container: 4
2023-10-31 22:32:08,995:INFO:LGBMRegressor(bagging_fraction=0.6, bagging_freq=2, feature_fraction=1.0,
              learning_rate=0.15, min_child_samples=61, min_split_gain=0.8,
              n_estimators=90, n_jobs=-1, num_leaves=70, random_state=123,
              reg_alpha=0.0001, reg_lambda=0.05)
2023-10-31 22:32:08,995:INFO:create_model() successfully completed......................................
2023-10-31 22:32:09,158:INFO:SubProcess create_model() end ==================================
2023-10-31 22:32:09,158:INFO:choose_better activated
2023-10-31 22:32:09,163:INFO:SubProcess create_model() called ==================================
2023-10-31 22:32:09,164:INFO:Initializing create_model()
2023-10-31 22:32:09,165:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001FEC8CB3700>, estimator=LGBMRegressor(n_jobs=-1, random_state=123), fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, kwargs={})
2023-10-31 22:32:09,165:INFO:Checking exceptions
2023-10-31 22:32:09,167:INFO:Importing libraries
2023-10-31 22:32:09,168:INFO:Copying training dataset
2023-10-31 22:32:09,173:INFO:Defining folds
2023-10-31 22:32:09,173:INFO:Declaring metric variables
2023-10-31 22:32:09,173:INFO:Importing untrained model
2023-10-31 22:32:09,173:INFO:Declaring custom model
2023-10-31 22:32:09,174:INFO:Light Gradient Boosting Machine Imported successfully
2023-10-31 22:32:09,174:INFO:Starting cross validation
2023-10-31 22:32:09,176:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-10-31 22:32:10,508:INFO:Calculating mean and std
2023-10-31 22:32:10,509:INFO:Creating metrics dataframe
2023-10-31 22:32:10,512:INFO:Finalizing model
2023-10-31 22:32:10,631:INFO:[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines
2023-10-31 22:32:10,633:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000638 seconds.
2023-10-31 22:32:10,633:INFO:You can set `force_row_wise=true` to remove the overhead.
2023-10-31 22:32:10,634:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2023-10-31 22:32:10,634:INFO:[LightGBM] [Info] Total Bins 282
2023-10-31 22:32:10,634:INFO:[LightGBM] [Info] Number of data points in the train set: 3322, number of used features: 18
2023-10-31 22:32:10,634:INFO:[LightGBM] [Info] Start training from score 34575.285370
2023-10-31 22:32:10,932:INFO:Uploading results into container
2023-10-31 22:32:10,933:INFO:Uploading model into container now
2023-10-31 22:32:10,933:INFO:_master_model_container: 21
2023-10-31 22:32:10,933:INFO:_display_container: 5
2023-10-31 22:32:10,934:INFO:LGBMRegressor(n_jobs=-1, random_state=123)
2023-10-31 22:32:10,934:INFO:create_model() successfully completed......................................
2023-10-31 22:32:11,089:INFO:SubProcess create_model() end ==================================
2023-10-31 22:32:11,090:INFO:LGBMRegressor(n_jobs=-1, random_state=123) result for R2 is 0.4826
2023-10-31 22:32:11,091:INFO:LGBMRegressor(bagging_fraction=0.6, bagging_freq=2, feature_fraction=1.0,
              learning_rate=0.15, min_child_samples=61, min_split_gain=0.8,
              n_estimators=90, n_jobs=-1, num_leaves=70, random_state=123,
              reg_alpha=0.0001, reg_lambda=0.05) result for R2 is 0.605
2023-10-31 22:32:11,091:INFO:LGBMRegressor(bagging_fraction=0.6, bagging_freq=2, feature_fraction=1.0,
              learning_rate=0.15, min_child_samples=61, min_split_gain=0.8,
              n_estimators=90, n_jobs=-1, num_leaves=70, random_state=123,
              reg_alpha=0.0001, reg_lambda=0.05) is best model
2023-10-31 22:32:11,091:INFO:choose_better completed
2023-10-31 22:32:11,102:INFO:_master_model_container: 21
2023-10-31 22:32:11,102:INFO:_display_container: 4
2023-10-31 22:32:11,103:INFO:LGBMRegressor(bagging_fraction=0.6, bagging_freq=2, feature_fraction=1.0,
              learning_rate=0.15, min_child_samples=61, min_split_gain=0.8,
              n_estimators=90, n_jobs=-1, num_leaves=70, random_state=123,
              reg_alpha=0.0001, reg_lambda=0.05)
2023-10-31 22:32:11,103:INFO:tune_model() successfully completed......................................
2023-10-31 22:33:41,323:INFO:Initializing finalize_model()
2023-10-31 22:33:41,323:INFO:finalize_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001FEC8CB3700>, estimator=LGBMRegressor(bagging_fraction=0.6, bagging_freq=2, feature_fraction=1.0,
              learning_rate=0.15, min_child_samples=61, min_split_gain=0.8,
              n_estimators=90, n_jobs=-1, num_leaves=70, random_state=123,
              reg_alpha=0.0001, reg_lambda=0.05), fit_kwargs=None, groups=None, model_only=False, experiment_custom_tags=None)
2023-10-31 22:33:41,324:INFO:Finalizing LGBMRegressor(bagging_fraction=0.6, bagging_freq=2, feature_fraction=1.0,
              learning_rate=0.15, min_child_samples=61, min_split_gain=0.8,
              n_estimators=90, n_jobs=-1, num_leaves=70, random_state=123,
              reg_alpha=0.0001, reg_lambda=0.05)
2023-10-31 22:33:41,328:INFO:Initializing create_model()
2023-10-31 22:33:41,328:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001FEC8CB3700>, estimator=LGBMRegressor(bagging_fraction=0.6, bagging_freq=2, feature_fraction=1.0,
              learning_rate=0.15, min_child_samples=61, min_split_gain=0.8,
              n_estimators=90, n_jobs=-1, num_leaves=70, random_state=123,
              reg_alpha=0.0001, reg_lambda=0.05), fold=None, round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=False, metrics=None, display=None, model_only=False, return_train_score=False, kwargs={})
2023-10-31 22:33:41,328:INFO:Checking exceptions
2023-10-31 22:33:41,331:INFO:Importing libraries
2023-10-31 22:33:41,331:INFO:Copying training dataset
2023-10-31 22:33:41,331:INFO:Defining folds
2023-10-31 22:33:41,332:INFO:Declaring metric variables
2023-10-31 22:33:41,332:INFO:Importing untrained model
2023-10-31 22:33:41,332:INFO:Declaring custom model
2023-10-31 22:33:41,333:INFO:Light Gradient Boosting Machine Imported successfully
2023-10-31 22:33:41,334:INFO:Cross validation set to False
2023-10-31 22:33:41,334:INFO:Fitting Model
2023-10-31 22:33:41,431:INFO:[LightGBM] [Warning] feature_fraction is set=1.0, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1.0
2023-10-31 22:33:41,432:INFO:[LightGBM] [Warning] bagging_fraction is set=0.6, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6
2023-10-31 22:33:41,432:INFO:[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=0 will be ignored. Current value: bagging_freq=2
2023-10-31 22:33:41,435:INFO:[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines
2023-10-31 22:33:41,436:INFO:[LightGBM] [Warning] feature_fraction is set=1.0, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1.0
2023-10-31 22:33:41,436:INFO:[LightGBM] [Warning] bagging_fraction is set=0.6, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6
2023-10-31 22:33:41,436:INFO:[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=0 will be ignored. Current value: bagging_freq=2
2023-10-31 22:33:41,439:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000550 seconds.
2023-10-31 22:33:41,439:INFO:You can set `force_row_wise=true` to remove the overhead.
2023-10-31 22:33:41,439:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2023-10-31 22:33:41,439:INFO:[LightGBM] [Info] Total Bins 289
2023-10-31 22:33:41,439:INFO:[LightGBM] [Info] Number of data points in the train set: 4746, number of used features: 18
2023-10-31 22:33:41,440:INFO:[LightGBM] [Info] Start training from score 34993.451327
2023-10-31 22:33:41,443:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-10-31 22:33:41,445:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-10-31 22:33:41,447:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-10-31 22:33:41,449:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-10-31 22:33:41,454:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-10-31 22:33:41,457:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-10-31 22:33:41,460:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-10-31 22:33:41,462:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-10-31 22:33:41,465:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-10-31 22:33:41,467:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-10-31 22:33:41,470:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-10-31 22:33:41,472:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-10-31 22:33:41,476:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-10-31 22:33:41,477:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-10-31 22:33:41,480:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-10-31 22:33:41,482:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-10-31 22:33:41,483:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-10-31 22:33:41,485:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-10-31 22:33:41,488:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-10-31 22:33:41,490:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-10-31 22:33:41,493:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-10-31 22:33:41,495:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-10-31 22:33:41,497:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-10-31 22:33:41,499:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-10-31 22:33:41,501:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-10-31 22:33:41,503:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-10-31 22:33:41,505:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-10-31 22:33:41,507:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-10-31 22:33:41,508:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-10-31 22:33:41,510:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-10-31 22:33:41,513:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-10-31 22:33:41,516:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-10-31 22:33:41,518:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-10-31 22:33:41,522:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-10-31 22:33:41,525:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-10-31 22:33:41,527:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-10-31 22:33:41,529:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-10-31 22:33:41,531:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-10-31 22:33:41,533:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-10-31 22:33:41,535:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-10-31 22:33:41,537:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-10-31 22:33:41,539:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-10-31 22:33:41,541:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-10-31 22:33:41,543:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-10-31 22:33:41,545:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-10-31 22:33:41,547:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-10-31 22:33:41,549:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-10-31 22:33:41,551:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-10-31 22:33:41,553:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-10-31 22:33:41,554:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-10-31 22:33:41,556:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-10-31 22:33:41,559:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-10-31 22:33:41,561:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-10-31 22:33:41,564:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-10-31 22:33:41,569:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-10-31 22:33:41,570:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-10-31 22:33:41,573:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-10-31 22:33:41,575:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-10-31 22:33:41,577:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-10-31 22:33:41,580:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-10-31 22:33:41,583:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-10-31 22:33:41,585:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-10-31 22:33:41,588:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-10-31 22:33:41,592:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-10-31 22:33:41,594:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-10-31 22:33:41,596:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-10-31 22:33:41,598:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-10-31 22:33:41,600:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-10-31 22:33:41,602:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-10-31 22:33:41,604:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-10-31 22:33:41,608:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-10-31 22:33:41,610:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-10-31 22:33:41,613:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-10-31 22:33:41,615:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-10-31 22:33:41,617:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-10-31 22:33:41,618:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-10-31 22:33:41,620:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-10-31 22:33:41,622:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-10-31 22:33:41,624:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-10-31 22:33:41,626:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-10-31 22:33:41,628:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-10-31 22:33:41,630:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-10-31 22:33:41,632:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-10-31 22:33:41,634:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-10-31 22:33:41,637:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-10-31 22:33:41,640:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-10-31 22:33:41,642:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-10-31 22:33:41,646:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-10-31 22:33:41,648:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-10-31 22:33:41,650:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-10-31 22:33:41,699:INFO:Pipeline(memory=Memory(location=None),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['BHK', 'Size', 'Bathroom'],
                                    transformer=SimpleImputer())),
                ('categorical_imputer',
                 TransformerWrapper(include=['Area Type', 'City',
                                             'Furnishing Status',
                                             'Tenant Preferred',
                                             'Point of Contact'],
                                    transformer=SimpleImputer(strategy='most_frequent'))),
                ('ordinal_encoding',
                 Tra...
                                                              handle_missing='return_nan',
                                                              use_cat_names=True))),
                ('clean_column_names',
                 TransformerWrapper(transformer=CleanColumnNames())),
                ('actual_estimator',
                 LGBMRegressor(bagging_fraction=0.6, bagging_freq=2,
                               feature_fraction=1.0, learning_rate=0.15,
                               min_child_samples=61, min_split_gain=0.8,
                               n_estimators=90, n_jobs=-1, num_leaves=70,
                               random_state=123, reg_alpha=0.0001,
                               reg_lambda=0.05))])
2023-10-31 22:33:41,700:INFO:create_model() successfully completed......................................
2023-10-31 22:33:41,872:INFO:_master_model_container: 21
2023-10-31 22:33:41,873:INFO:_display_container: 4
2023-10-31 22:33:41,902:INFO:Pipeline(memory=Memory(location=None),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['BHK', 'Size', 'Bathroom'],
                                    transformer=SimpleImputer())),
                ('categorical_imputer',
                 TransformerWrapper(include=['Area Type', 'City',
                                             'Furnishing Status',
                                             'Tenant Preferred',
                                             'Point of Contact'],
                                    transformer=SimpleImputer(strategy='most_frequent'))),
                ('ordinal_encoding',
                 Tra...
                                                              handle_missing='return_nan',
                                                              use_cat_names=True))),
                ('clean_column_names',
                 TransformerWrapper(transformer=CleanColumnNames())),
                ('actual_estimator',
                 LGBMRegressor(bagging_fraction=0.6, bagging_freq=2,
                               feature_fraction=1.0, learning_rate=0.15,
                               min_child_samples=61, min_split_gain=0.8,
                               n_estimators=90, n_jobs=-1, num_leaves=70,
                               random_state=123, reg_alpha=0.0001,
                               reg_lambda=0.05))])
2023-10-31 22:33:41,902:INFO:finalize_model() successfully completed......................................
2023-10-31 22:34:29,030:INFO:Initializing save_model()
2023-10-31 22:34:29,030:INFO:save_model(model=Pipeline(memory=Memory(location=None),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['BHK', 'Size', 'Bathroom'],
                                    transformer=SimpleImputer())),
                ('categorical_imputer',
                 TransformerWrapper(include=['Area Type', 'City',
                                             'Furnishing Status',
                                             'Tenant Preferred',
                                             'Point of Contact'],
                                    transformer=SimpleImputer(strategy='most_frequent'))),
                ('ordinal_encoding',
                 Tra...
                                                              handle_missing='return_nan',
                                                              use_cat_names=True))),
                ('clean_column_names',
                 TransformerWrapper(transformer=CleanColumnNames())),
                ('actual_estimator',
                 LGBMRegressor(bagging_fraction=0.6, bagging_freq=2,
                               feature_fraction=1.0, learning_rate=0.15,
                               min_child_samples=61, min_split_gain=0.8,
                               n_estimators=90, n_jobs=-1, num_leaves=70,
                               random_state=123, reg_alpha=0.0001,
                               reg_lambda=0.05))]), model_name=model_lgb, prep_pipe_=Pipeline(memory=FastMemory(location=C:\Users\CHRIST~1\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['BHK', 'Size', 'Bathroom'],
                                    transformer=SimpleImputer())),
                ('categorical_imputer',
                 TransformerWrapper(include=['Area Type', 'City',
                                             'Furnishing Status',
                                             'Tenant Preferred',
                                             'Point of Contact'],
                                    transformer=SimpleImputer(strategy...
Contact Owner    1
NaN             -1
dtype: int64}]))),
                ('onehot_encoding',
                 TransformerWrapper(include=['Area Type', 'City',
                                             'Furnishing Status',
                                             'Tenant Preferred'],
                                    transformer=OneHotEncoder(cols=['Area Type',
                                                                    'City',
                                                                    'Furnishing '
                                                                    'Status',
                                                                    'Tenant '
                                                                    'Preferred'],
                                                              handle_missing='return_nan',
                                                              use_cat_names=True))),
                ('clean_column_names',
                 TransformerWrapper(transformer=CleanColumnNames()))]), verbose=True, use_case=MLUsecase.REGRESSION, kwargs={})
2023-10-31 22:34:29,030:INFO:Adding model into prep_pipe
2023-10-31 22:34:29,030:WARNING:Only Model saved as it was a pipeline.
2023-10-31 22:34:29,047:INFO:model_lgb.pkl saved in current working directory
2023-10-31 22:34:29,083:INFO:Pipeline(memory=Memory(location=None),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['BHK', 'Size', 'Bathroom'],
                                    transformer=SimpleImputer())),
                ('categorical_imputer',
                 TransformerWrapper(include=['Area Type', 'City',
                                             'Furnishing Status',
                                             'Tenant Preferred',
                                             'Point of Contact'],
                                    transformer=SimpleImputer(strategy='most_frequent'))),
                ('ordinal_encoding',
                 Tra...
                                                              handle_missing='return_nan',
                                                              use_cat_names=True))),
                ('clean_column_names',
                 TransformerWrapper(transformer=CleanColumnNames())),
                ('actual_estimator',
                 LGBMRegressor(bagging_fraction=0.6, bagging_freq=2,
                               feature_fraction=1.0, learning_rate=0.15,
                               min_child_samples=61, min_split_gain=0.8,
                               n_estimators=90, n_jobs=-1, num_leaves=70,
                               random_state=123, reg_alpha=0.0001,
                               reg_lambda=0.05))])
2023-10-31 22:34:29,083:INFO:save_model() successfully completed......................................
2023-11-02 19:46:48,921:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-11-02 19:46:48,929:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-11-02 19:46:48,929:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-11-02 19:46:48,930:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-11-02 19:49:42,564:INFO:PyCaret RegressionExperiment
2023-11-02 19:49:42,564:INFO:Logging name: model_rent_lgbm
2023-11-02 19:49:42,564:INFO:ML Usecase: MLUsecase.REGRESSION
2023-11-02 19:49:42,564:INFO:version 3.1.0
2023-11-02 19:49:42,564:INFO:Initializing setup()
2023-11-02 19:49:42,565:INFO:self.USI: 5e2f
2023-11-02 19:49:42,565:INFO:self._variable_keys: {'y_test', 'gpu_n_jobs_param', 'seed', 'exp_name_log', 'X_test', 'X', 'transform_target_param', 'X_train', 'exp_id', 'fold_groups_param', '_ml_usecase', 'memory', '_available_plots', 'idx', 'data', 'html_param', 'pipeline', 'y_train', 'logging_param', 'fold_generator', 'gpu_param', 'USI', 'fold_shuffle_param', 'log_plots_param', 'n_jobs_param', 'y', 'target_param'}
2023-11-02 19:49:42,565:INFO:Checking environment
2023-11-02 19:49:42,565:INFO:python_version: 3.8.5
2023-11-02 19:49:42,565:INFO:python_build: ('tags/v3.8.5:580fbb0', 'Jul 20 2020 15:57:54')
2023-11-02 19:49:42,565:INFO:machine: AMD64
2023-11-02 19:49:42,565:INFO:platform: Windows-10-10.0.19041-SP0
2023-11-02 19:49:42,584:INFO:Memory: svmem(total=137304428544, available=87251271680, percent=36.5, used=50053156864, free=87251271680)
2023-11-02 19:49:42,584:INFO:Physical Core: 16
2023-11-02 19:49:42,584:INFO:Logical Core: 32
2023-11-02 19:49:42,584:INFO:Checking libraries
2023-11-02 19:49:42,584:INFO:System:
2023-11-02 19:49:42,584:INFO:    python: 3.8.5 (tags/v3.8.5:580fbb0, Jul 20 2020, 15:57:54) [MSC v.1924 64 bit (AMD64)]
2023-11-02 19:49:42,584:INFO:executable: d:\trabajo\dmc\202311\pea da\pea_da\scripts\python.exe
2023-11-02 19:49:42,584:INFO:   machine: Windows-10-10.0.19041-SP0
2023-11-02 19:49:42,584:INFO:PyCaret required dependencies:
2023-11-02 19:49:42,705:INFO:                 pip: 20.1.1
2023-11-02 19:49:42,705:INFO:          setuptools: 47.1.0
2023-11-02 19:49:42,705:INFO:             pycaret: 3.1.0
2023-11-02 19:49:42,705:INFO:             IPython: 8.12.3
2023-11-02 19:49:42,705:INFO:          ipywidgets: 8.1.1
2023-11-02 19:49:42,705:INFO:                tqdm: 4.66.1
2023-11-02 19:49:42,705:INFO:               numpy: 1.23.5
2023-11-02 19:49:42,706:INFO:              pandas: 1.5.3
2023-11-02 19:49:42,706:INFO:              jinja2: 3.1.2
2023-11-02 19:49:42,706:INFO:               scipy: 1.10.1
2023-11-02 19:49:42,706:INFO:              joblib: 1.3.2
2023-11-02 19:49:42,706:INFO:             sklearn: 1.2.2
2023-11-02 19:49:42,706:INFO:                pyod: 1.1.1
2023-11-02 19:49:42,706:INFO:            imblearn: 0.11.0
2023-11-02 19:49:42,706:INFO:   category_encoders: 2.6.3
2023-11-02 19:49:42,706:INFO:            lightgbm: 4.1.0
2023-11-02 19:49:42,706:INFO:               numba: 0.58.1
2023-11-02 19:49:42,706:INFO:            requests: 2.31.0
2023-11-02 19:49:42,706:INFO:          matplotlib: 3.7.3
2023-11-02 19:49:42,706:INFO:          scikitplot: 0.3.7
2023-11-02 19:49:42,706:INFO:         yellowbrick: 1.5
2023-11-02 19:49:42,706:INFO:              plotly: 5.18.0
2023-11-02 19:49:42,706:INFO:    plotly-resampler: Not installed
2023-11-02 19:49:42,706:INFO:             kaleido: 0.2.1
2023-11-02 19:49:42,706:INFO:           schemdraw: 0.15
2023-11-02 19:49:42,706:INFO:         statsmodels: 0.14.0
2023-11-02 19:49:42,706:INFO:              sktime: 0.21.1
2023-11-02 19:49:42,706:INFO:               tbats: 1.1.3
2023-11-02 19:49:42,706:INFO:            pmdarima: 2.0.4
2023-11-02 19:49:42,706:INFO:              psutil: 5.9.6
2023-11-02 19:49:42,706:INFO:          markupsafe: 2.1.3
2023-11-02 19:49:42,706:INFO:             pickle5: Not installed
2023-11-02 19:49:42,707:INFO:         cloudpickle: 2.2.1
2023-11-02 19:49:42,707:INFO:         deprecation: 2.1.0
2023-11-02 19:49:42,707:INFO:              xxhash: 3.4.1
2023-11-02 19:49:42,707:INFO:           wurlitzer: Not installed
2023-11-02 19:49:42,707:INFO:PyCaret optional dependencies:
2023-11-02 19:49:42,719:INFO:                shap: Not installed
2023-11-02 19:49:42,719:INFO:           interpret: Not installed
2023-11-02 19:49:42,719:INFO:                umap: Not installed
2023-11-02 19:49:42,719:INFO:     ydata_profiling: Not installed
2023-11-02 19:49:42,719:INFO:  explainerdashboard: Not installed
2023-11-02 19:49:42,719:INFO:             autoviz: Not installed
2023-11-02 19:49:42,719:INFO:           fairlearn: Not installed
2023-11-02 19:49:42,719:INFO:          deepchecks: Not installed
2023-11-02 19:49:42,719:INFO:             xgboost: Not installed
2023-11-02 19:49:42,719:INFO:            catboost: Not installed
2023-11-02 19:49:42,719:INFO:              kmodes: Not installed
2023-11-02 19:49:42,719:INFO:             mlxtend: Not installed
2023-11-02 19:49:42,719:INFO:       statsforecast: Not installed
2023-11-02 19:49:42,719:INFO:        tune_sklearn: Not installed
2023-11-02 19:49:42,719:INFO:                 ray: Not installed
2023-11-02 19:49:42,719:INFO:            hyperopt: Not installed
2023-11-02 19:49:42,719:INFO:              optuna: Not installed
2023-11-02 19:49:42,719:INFO:               skopt: Not installed
2023-11-02 19:49:42,720:INFO:              mlflow: 2.8.0
2023-11-02 19:49:42,720:INFO:              gradio: Not installed
2023-11-02 19:49:42,720:INFO:             fastapi: Not installed
2023-11-02 19:49:42,720:INFO:             uvicorn: Not installed
2023-11-02 19:49:42,720:INFO:              m2cgen: Not installed
2023-11-02 19:49:42,720:INFO:           evidently: Not installed
2023-11-02 19:49:42,720:INFO:               fugue: Not installed
2023-11-02 19:49:42,720:INFO:           streamlit: Not installed
2023-11-02 19:49:42,720:INFO:             prophet: Not installed
2023-11-02 19:49:42,720:INFO:None
2023-11-02 19:49:42,720:INFO:Set up data.
2023-11-02 19:49:42,756:INFO:Set up folding strategy.
2023-11-02 19:49:42,756:INFO:Set up train/test split.
2023-11-02 19:49:42,791:INFO:Set up index.
2023-11-02 19:49:42,792:INFO:Assigning column types.
2023-11-02 19:49:42,795:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2023-11-02 19:49:42,796:INFO:Engine for model 'lasso' has not been set explicitly, hence returning None.
2023-11-02 19:49:42,802:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2023-11-02 19:49:42,809:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-11-02 19:49:42,904:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-11-02 19:49:42,970:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-11-02 19:49:42,971:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-11-02 19:49:42,971:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-11-02 19:49:42,971:INFO:Engine for model 'lasso' has not been set explicitly, hence returning None.
2023-11-02 19:49:42,978:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2023-11-02 19:49:42,985:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-11-02 19:49:43,071:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-11-02 19:49:43,143:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-11-02 19:49:43,143:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-11-02 19:49:43,144:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-11-02 19:49:43,144:INFO:Engine successfully changes for model 'lasso' to 'sklearn'.
2023-11-02 19:49:43,151:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2023-11-02 19:49:43,158:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-11-02 19:49:43,244:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-11-02 19:49:43,317:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-11-02 19:49:43,318:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-11-02 19:49:43,318:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-11-02 19:49:43,325:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2023-11-02 19:49:43,332:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-11-02 19:49:43,417:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-11-02 19:49:43,481:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-11-02 19:49:43,482:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-11-02 19:49:43,482:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-11-02 19:49:43,483:INFO:Engine successfully changes for model 'ridge' to 'sklearn'.
2023-11-02 19:49:43,496:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-11-02 19:49:43,591:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-11-02 19:49:43,657:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-11-02 19:49:43,658:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-11-02 19:49:43,658:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-11-02 19:49:43,673:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-11-02 19:49:43,766:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-11-02 19:49:43,836:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-11-02 19:49:43,837:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-11-02 19:49:43,837:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-11-02 19:49:43,837:INFO:Engine successfully changes for model 'en' to 'sklearn'.
2023-11-02 19:49:43,959:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-11-02 19:49:44,034:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-11-02 19:49:44,034:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-11-02 19:49:44,035:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-11-02 19:49:44,147:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-11-02 19:49:44,221:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-11-02 19:49:44,227:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-11-02 19:49:44,227:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-11-02 19:49:44,228:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2023-11-02 19:49:44,335:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-11-02 19:49:44,404:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-11-02 19:49:44,404:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-11-02 19:49:44,510:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-11-02 19:49:44,583:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-11-02 19:49:44,583:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-11-02 19:49:44,584:INFO:Engine successfully changes for model 'svm' to 'sklearn'.
2023-11-02 19:49:44,756:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-11-02 19:49:44,757:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-11-02 19:49:44,926:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-11-02 19:49:44,926:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-11-02 19:49:44,949:INFO:Preparing preprocessing pipeline...
2023-11-02 19:49:44,949:INFO:Set up simple imputation.
2023-11-02 19:49:44,963:INFO:Set up encoding of ordinal features.
2023-11-02 19:49:44,965:WARNING:The number of classes passed to feature Point of Contact in the ordinal_features parameter (2) don't match with the number of classes in the data (3).
2023-11-02 19:49:44,966:INFO:Set up encoding of categorical features.
2023-11-02 19:49:44,966:INFO:Set up column name cleaning.
2023-11-02 19:49:45,126:INFO:Finished creating preprocessing pipeline.
2023-11-02 19:49:45,167:INFO:Pipeline: Pipeline(memory=FastMemory(location=C:\Users\CHRIST~1\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['BHK', 'Size', 'Bathroom'],
                                    transformer=SimpleImputer())),
                ('categorical_imputer',
                 TransformerWrapper(include=['Area Type', 'City',
                                             'Furnishing Status',
                                             'Tenant Preferred',
                                             'Point of Contact'],
                                    transformer=SimpleImputer(strategy...
Contact Owner    1
NaN             -1
dtype: int64}]))),
                ('onehot_encoding',
                 TransformerWrapper(include=['Area Type', 'City',
                                             'Furnishing Status',
                                             'Tenant Preferred'],
                                    transformer=OneHotEncoder(cols=['Area Type',
                                                                    'City',
                                                                    'Furnishing '
                                                                    'Status',
                                                                    'Tenant '
                                                                    'Preferred'],
                                                              handle_missing='return_nan',
                                                              use_cat_names=True))),
                ('clean_column_names',
                 TransformerWrapper(transformer=CleanColumnNames()))])
2023-11-02 19:49:45,167:INFO:Creating final display dataframe.
2023-11-02 19:49:45,496:INFO:Setup _display_container:                     Description            Value
0                    Session id              123
1                        Target             Rent
2                   Target type       Regression
3           Original data shape       (4746, 12)
4        Transformed data shape       (4746, 20)
5   Transformed train set shape       (3322, 20)
6    Transformed test set shape       (1424, 20)
7               Ignore features                3
8              Ordinal features                1
9              Numeric features                3
10         Categorical features                5
11                   Preprocess             True
12              Imputation type           simple
13           Numeric imputation             mean
14       Categorical imputation             mode
15     Maximum one-hot encoding               25
16              Encoding method             None
17               Fold Generator            KFold
18                  Fold Number               10
19                     CPU Jobs               -1
20                      Use GPU            False
21               Log Experiment     MlflowLogger
22              Experiment Name  model_rent_lgbm
23                          USI             5e2f
2023-11-02 19:49:45,681:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-11-02 19:49:45,681:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-11-02 19:49:45,850:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-11-02 19:49:45,851:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-11-02 19:49:45,851:INFO:Logging experiment in loggers
2023-11-02 19:49:46,366:INFO:SubProcess save_model() called ==================================
2023-11-02 19:49:46,417:INFO:Initializing save_model()
2023-11-02 19:49:46,417:INFO:save_model(model=Pipeline(memory=FastMemory(location=C:\Users\CHRIST~1\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['BHK', 'Size', 'Bathroom'],
                                    transformer=SimpleImputer())),
                ('categorical_imputer',
                 TransformerWrapper(include=['Area Type', 'City',
                                             'Furnishing Status',
                                             'Tenant Preferred',
                                             'Point of Contact'],
                                    transformer=SimpleImputer(strategy...
Contact Owner    1
NaN             -1
dtype: int64}]))),
                ('onehot_encoding',
                 TransformerWrapper(include=['Area Type', 'City',
                                             'Furnishing Status',
                                             'Tenant Preferred'],
                                    transformer=OneHotEncoder(cols=['Area Type',
                                                                    'City',
                                                                    'Furnishing '
                                                                    'Status',
                                                                    'Tenant '
                                                                    'Preferred'],
                                                              handle_missing='return_nan',
                                                              use_cat_names=True))),
                ('clean_column_names',
                 TransformerWrapper(transformer=CleanColumnNames()))]), model_name=C:\Users\CHRIST~1\AppData\Local\Temp\tmp1chm7gtk\Transformation Pipeline, prep_pipe_=Pipeline(memory=FastMemory(location=C:\Users\CHRIST~1\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['BHK', 'Size', 'Bathroom'],
                                    transformer=SimpleImputer())),
                ('categorical_imputer',
                 TransformerWrapper(include=['Area Type', 'City',
                                             'Furnishing Status',
                                             'Tenant Preferred',
                                             'Point of Contact'],
                                    transformer=SimpleImputer(strategy...
Contact Owner    1
NaN             -1
dtype: int64}]))),
                ('onehot_encoding',
                 TransformerWrapper(include=['Area Type', 'City',
                                             'Furnishing Status',
                                             'Tenant Preferred'],
                                    transformer=OneHotEncoder(cols=['Area Type',
                                                                    'City',
                                                                    'Furnishing '
                                                                    'Status',
                                                                    'Tenant '
                                                                    'Preferred'],
                                                              handle_missing='return_nan',
                                                              use_cat_names=True))),
                ('clean_column_names',
                 TransformerWrapper(transformer=CleanColumnNames()))]), verbose=False, use_case=MLUsecase.REGRESSION, kwargs={})
2023-11-02 19:49:46,418:INFO:Adding model into prep_pipe
2023-11-02 19:49:46,418:WARNING:Only Model saved as it was a pipeline.
2023-11-02 19:49:46,426:INFO:C:\Users\CHRIST~1\AppData\Local\Temp\tmp1chm7gtk\Transformation Pipeline.pkl saved in current working directory
2023-11-02 19:49:46,453:INFO:Pipeline(memory=FastMemory(location=C:\Users\CHRIST~1\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['BHK', 'Size', 'Bathroom'],
                                    transformer=SimpleImputer())),
                ('categorical_imputer',
                 TransformerWrapper(include=['Area Type', 'City',
                                             'Furnishing Status',
                                             'Tenant Preferred',
                                             'Point of Contact'],
                                    transformer=SimpleImputer(strategy...
Contact Owner    1
NaN             -1
dtype: int64}]))),
                ('onehot_encoding',
                 TransformerWrapper(include=['Area Type', 'City',
                                             'Furnishing Status',
                                             'Tenant Preferred'],
                                    transformer=OneHotEncoder(cols=['Area Type',
                                                                    'City',
                                                                    'Furnishing '
                                                                    'Status',
                                                                    'Tenant '
                                                                    'Preferred'],
                                                              handle_missing='return_nan',
                                                              use_cat_names=True))),
                ('clean_column_names',
                 TransformerWrapper(transformer=CleanColumnNames()))])
2023-11-02 19:49:46,454:INFO:save_model() successfully completed......................................
2023-11-02 19:49:46,628:INFO:SubProcess save_model() end ==================================
2023-11-02 19:49:46,734:INFO:setup() successfully completed in 3.73s...............
2023-11-02 19:50:37,230:INFO:Initializing create_model()
2023-11-02 19:50:37,230:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001856BE64130>, estimator=lightgbm, fold=None, round=4, cross_validation=True, predict=True, fit_kwargs=None, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=True, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, kwargs={})
2023-11-02 19:50:37,230:INFO:Checking exceptions
2023-11-02 19:50:37,246:INFO:Importing libraries
2023-11-02 19:50:37,246:INFO:Copying training dataset
2023-11-02 19:50:37,251:INFO:Defining folds
2023-11-02 19:50:37,252:INFO:Declaring metric variables
2023-11-02 19:50:37,255:INFO:Importing untrained model
2023-11-02 19:50:37,259:INFO:Light Gradient Boosting Machine Imported successfully
2023-11-02 19:50:37,265:INFO:Starting cross validation
2023-11-02 19:50:37,321:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-11-02 19:50:41,939:INFO:Calculating mean and std
2023-11-02 19:50:41,942:INFO:Creating metrics dataframe
2023-11-02 19:50:41,949:INFO:Finalizing model
2023-11-02 19:50:42,071:INFO:[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines
2023-11-02 19:50:42,074:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000656 seconds.
2023-11-02 19:50:42,074:INFO:You can set `force_row_wise=true` to remove the overhead.
2023-11-02 19:50:42,074:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2023-11-02 19:50:42,074:INFO:[LightGBM] [Info] Total Bins 282
2023-11-02 19:50:42,074:INFO:[LightGBM] [Info] Number of data points in the train set: 3322, number of used features: 18
2023-11-02 19:50:42,075:INFO:[LightGBM] [Info] Start training from score 34575.285370
2023-11-02 19:50:42,300:INFO:Creating Dashboard logs
2023-11-02 19:50:42,306:INFO:Model: Light Gradient Boosting Machine
2023-11-02 19:50:42,382:INFO:Logged params: {'boosting_type': 'gbdt', 'class_weight': None, 'colsample_bytree': 1.0, 'importance_type': 'split', 'learning_rate': 0.1, 'max_depth': -1, 'min_child_samples': 20, 'min_child_weight': 0.001, 'min_split_gain': 0.0, 'n_estimators': 100, 'n_jobs': -1, 'num_leaves': 31, 'objective': None, 'random_state': 123, 'reg_alpha': 0.0, 'reg_lambda': 0.0, 'subsample': 1.0, 'subsample_for_bin': 200000, 'subsample_freq': 0}
2023-11-02 19:50:42,641:INFO:Initializing predict_model()
2023-11-02 19:50:42,641:INFO:predict_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001856BE64130>, estimator=LGBMRegressor(n_jobs=-1, random_state=123), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=False, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x000001856C993940>)
2023-11-02 19:50:42,641:INFO:Checking exceptions
2023-11-02 19:50:42,641:INFO:Preloading libraries
2023-11-02 19:50:43,515:INFO:Uploading results into container
2023-11-02 19:50:43,516:INFO:Uploading model into container now
2023-11-02 19:50:43,527:INFO:_master_model_container: 1
2023-11-02 19:50:43,527:INFO:_display_container: 2
2023-11-02 19:50:43,528:INFO:LGBMRegressor(n_jobs=-1, random_state=123)
2023-11-02 19:50:43,528:INFO:create_model() successfully completed......................................
2023-11-02 19:54:25,199:INFO:Initializing tune_model()
2023-11-02 19:54:25,199:INFO:tune_model(estimator=LGBMRegressor(n_jobs=-1, random_state=123), fold=None, round=4, n_iter=20, custom_grid=None, optimize=R2, custom_scorer=None, search_library=scikit-learn, search_algorithm=None, early_stopping=False, early_stopping_max_iters=10, choose_better=True, fit_kwargs=None, groups=None, return_tuner=False, verbose=True, tuner_verbose=True, return_train_score=False, kwargs={}, self=<pycaret.regression.oop.RegressionExperiment object at 0x000001856BE64130>)
2023-11-02 19:54:25,199:INFO:Checking exceptions
2023-11-02 19:54:25,215:INFO:Copying training dataset
2023-11-02 19:54:25,220:INFO:Checking base model
2023-11-02 19:54:25,220:INFO:Base model : Light Gradient Boosting Machine
2023-11-02 19:54:25,224:INFO:Declaring metric variables
2023-11-02 19:54:25,228:INFO:Defining Hyperparameters
2023-11-02 19:54:25,400:INFO:Tuning with n_jobs=-1
2023-11-02 19:54:25,400:INFO:Initializing RandomizedSearchCV
2023-11-02 19:54:47,931:INFO:best_params: {'actual_estimator__reg_lambda': 0.05, 'actual_estimator__reg_alpha': 0.0001, 'actual_estimator__num_leaves': 70, 'actual_estimator__n_estimators': 90, 'actual_estimator__min_split_gain': 0.8, 'actual_estimator__min_child_samples': 61, 'actual_estimator__learning_rate': 0.15, 'actual_estimator__feature_fraction': 1.0, 'actual_estimator__bagging_freq': 2, 'actual_estimator__bagging_fraction': 0.6}
2023-11-02 19:54:47,933:INFO:Hyperparameter search completed
2023-11-02 19:54:47,933:INFO:SubProcess create_model() called ==================================
2023-11-02 19:54:47,934:INFO:Initializing create_model()
2023-11-02 19:54:47,934:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001856BE64130>, estimator=LGBMRegressor(n_jobs=-1, random_state=123), fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001856DD28190>, model_only=True, return_train_score=False, kwargs={'reg_lambda': 0.05, 'reg_alpha': 0.0001, 'num_leaves': 70, 'n_estimators': 90, 'min_split_gain': 0.8, 'min_child_samples': 61, 'learning_rate': 0.15, 'feature_fraction': 1.0, 'bagging_freq': 2, 'bagging_fraction': 0.6})
2023-11-02 19:54:47,934:INFO:Checking exceptions
2023-11-02 19:54:47,934:INFO:Importing libraries
2023-11-02 19:54:47,935:INFO:Copying training dataset
2023-11-02 19:54:47,941:INFO:Defining folds
2023-11-02 19:54:47,941:INFO:Declaring metric variables
2023-11-02 19:54:47,946:INFO:Importing untrained model
2023-11-02 19:54:47,946:INFO:Declaring custom model
2023-11-02 19:54:47,952:INFO:Light Gradient Boosting Machine Imported successfully
2023-11-02 19:54:47,963:INFO:Starting cross validation
2023-11-02 19:54:47,966:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-11-02 19:54:49,023:INFO:Calculating mean and std
2023-11-02 19:54:49,025:INFO:Creating metrics dataframe
2023-11-02 19:54:49,032:INFO:Finalizing model
2023-11-02 19:54:49,137:INFO:[LightGBM] [Warning] feature_fraction is set=1.0, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1.0
2023-11-02 19:54:49,137:INFO:[LightGBM] [Warning] bagging_fraction is set=0.6, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6
2023-11-02 19:54:49,137:INFO:[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=0 will be ignored. Current value: bagging_freq=2
2023-11-02 19:54:49,140:INFO:[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines
2023-11-02 19:54:49,140:INFO:[LightGBM] [Warning] feature_fraction is set=1.0, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1.0
2023-11-02 19:54:49,140:INFO:[LightGBM] [Warning] bagging_fraction is set=0.6, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6
2023-11-02 19:54:49,141:INFO:[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=0 will be ignored. Current value: bagging_freq=2
2023-11-02 19:54:49,142:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000488 seconds.
2023-11-02 19:54:49,142:INFO:You can set `force_row_wise=true` to remove the overhead.
2023-11-02 19:54:49,142:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2023-11-02 19:54:49,142:INFO:[LightGBM] [Info] Total Bins 282
2023-11-02 19:54:49,143:INFO:[LightGBM] [Info] Number of data points in the train set: 3322, number of used features: 18
2023-11-02 19:54:49,143:INFO:[LightGBM] [Info] Start training from score 34575.285370
2023-11-02 19:54:49,145:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-02 19:54:49,146:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-02 19:54:49,148:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-02 19:54:49,150:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-02 19:54:49,153:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-02 19:54:49,154:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-02 19:54:49,156:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-02 19:54:49,160:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-02 19:54:49,161:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-02 19:54:49,162:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-02 19:54:49,166:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-02 19:54:49,168:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-02 19:54:49,170:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-02 19:54:49,172:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-02 19:54:49,175:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-02 19:54:49,177:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-02 19:54:49,178:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-02 19:54:49,180:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-02 19:54:49,182:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-02 19:54:49,183:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-02 19:54:49,185:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-02 19:54:49,186:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-02 19:54:49,187:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-02 19:54:49,189:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-02 19:54:49,190:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-02 19:54:49,192:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-02 19:54:49,194:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-02 19:54:49,195:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-02 19:54:49,197:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-02 19:54:49,198:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-02 19:54:49,199:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-02 19:54:49,201:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-02 19:54:49,202:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-02 19:54:49,203:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-02 19:54:49,205:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-02 19:54:49,209:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-02 19:54:49,213:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-02 19:54:49,214:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-02 19:54:49,217:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-02 19:54:49,219:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-02 19:54:49,222:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-02 19:54:49,224:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-02 19:54:49,225:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-02 19:54:49,227:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-02 19:54:49,229:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-02 19:54:49,230:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-02 19:54:49,232:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-02 19:54:49,233:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-02 19:54:49,235:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-02 19:54:49,236:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-02 19:54:49,237:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-02 19:54:49,239:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-02 19:54:49,241:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-02 19:54:49,243:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-02 19:54:49,245:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-02 19:54:49,246:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-02 19:54:49,247:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-02 19:54:49,249:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-02 19:54:49,250:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-02 19:54:49,251:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-02 19:54:49,253:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-02 19:54:49,254:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-02 19:54:49,258:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-02 19:54:49,261:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-02 19:54:49,263:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-02 19:54:49,265:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-02 19:54:49,266:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-02 19:54:49,267:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-02 19:54:49,269:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-02 19:54:49,270:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-02 19:54:49,271:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-02 19:54:49,273:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-02 19:54:49,275:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-02 19:54:49,276:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-02 19:54:49,279:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-02 19:54:49,281:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-02 19:54:49,282:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-02 19:54:49,286:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-02 19:54:49,287:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-02 19:54:49,289:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-02 19:54:49,292:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-02 19:54:49,294:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-02 19:54:49,295:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-02 19:54:49,297:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-02 19:54:49,299:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-02 19:54:49,301:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-02 19:54:49,302:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-02 19:54:49,304:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-02 19:54:49,306:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-02 19:54:49,307:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-02 19:54:49,325:INFO:Uploading results into container
2023-11-02 19:54:49,326:INFO:Uploading model into container now
2023-11-02 19:54:49,327:INFO:_master_model_container: 2
2023-11-02 19:54:49,327:INFO:_display_container: 3
2023-11-02 19:54:49,328:INFO:LGBMRegressor(bagging_fraction=0.6, bagging_freq=2, feature_fraction=1.0,
              learning_rate=0.15, min_child_samples=61, min_split_gain=0.8,
              n_estimators=90, n_jobs=-1, num_leaves=70, random_state=123,
              reg_alpha=0.0001, reg_lambda=0.05)
2023-11-02 19:54:49,328:INFO:create_model() successfully completed......................................
2023-11-02 19:54:49,531:INFO:SubProcess create_model() end ==================================
2023-11-02 19:54:49,531:INFO:choose_better activated
2023-11-02 19:54:49,536:INFO:SubProcess create_model() called ==================================
2023-11-02 19:54:49,537:INFO:Initializing create_model()
2023-11-02 19:54:49,537:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001856BE64130>, estimator=LGBMRegressor(n_jobs=-1, random_state=123), fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, kwargs={})
2023-11-02 19:54:49,537:INFO:Checking exceptions
2023-11-02 19:54:49,539:INFO:Importing libraries
2023-11-02 19:54:49,540:INFO:Copying training dataset
2023-11-02 19:54:49,547:INFO:Defining folds
2023-11-02 19:54:49,547:INFO:Declaring metric variables
2023-11-02 19:54:49,547:INFO:Importing untrained model
2023-11-02 19:54:49,547:INFO:Declaring custom model
2023-11-02 19:54:49,548:INFO:Light Gradient Boosting Machine Imported successfully
2023-11-02 19:54:49,548:INFO:Starting cross validation
2023-11-02 19:54:49,550:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-11-02 19:54:50,631:INFO:Calculating mean and std
2023-11-02 19:54:50,632:INFO:Creating metrics dataframe
2023-11-02 19:54:50,635:INFO:Finalizing model
2023-11-02 19:54:50,739:INFO:[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines
2023-11-02 19:54:50,742:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001419 seconds.
2023-11-02 19:54:50,742:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-11-02 19:54:50,742:INFO:[LightGBM] [Info] Total Bins 282
2023-11-02 19:54:50,742:INFO:[LightGBM] [Info] Number of data points in the train set: 3322, number of used features: 18
2023-11-02 19:54:50,743:INFO:[LightGBM] [Info] Start training from score 34575.285370
2023-11-02 19:54:50,991:INFO:Uploading results into container
2023-11-02 19:54:50,993:INFO:Uploading model into container now
2023-11-02 19:54:50,993:INFO:_master_model_container: 3
2023-11-02 19:54:50,994:INFO:_display_container: 4
2023-11-02 19:54:50,994:INFO:LGBMRegressor(n_jobs=-1, random_state=123)
2023-11-02 19:54:50,994:INFO:create_model() successfully completed......................................
2023-11-02 19:54:51,179:INFO:SubProcess create_model() end ==================================
2023-11-02 19:54:51,179:INFO:LGBMRegressor(n_jobs=-1, random_state=123) result for R2 is 0.4826
2023-11-02 19:54:51,180:INFO:LGBMRegressor(bagging_fraction=0.6, bagging_freq=2, feature_fraction=1.0,
              learning_rate=0.15, min_child_samples=61, min_split_gain=0.8,
              n_estimators=90, n_jobs=-1, num_leaves=70, random_state=123,
              reg_alpha=0.0001, reg_lambda=0.05) result for R2 is 0.605
2023-11-02 19:54:51,181:INFO:LGBMRegressor(bagging_fraction=0.6, bagging_freq=2, feature_fraction=1.0,
              learning_rate=0.15, min_child_samples=61, min_split_gain=0.8,
              n_estimators=90, n_jobs=-1, num_leaves=70, random_state=123,
              reg_alpha=0.0001, reg_lambda=0.05) is best model
2023-11-02 19:54:51,181:INFO:choose_better completed
2023-11-02 19:54:51,181:INFO:Creating Dashboard logs
2023-11-02 19:54:51,185:INFO:Model: Light Gradient Boosting Machine
2023-11-02 19:54:51,244:INFO:Logged params: {'boosting_type': 'gbdt', 'class_weight': None, 'colsample_bytree': 1.0, 'importance_type': 'split', 'learning_rate': 0.15, 'max_depth': -1, 'min_child_samples': 61, 'min_child_weight': 0.001, 'min_split_gain': 0.8, 'n_estimators': 90, 'n_jobs': -1, 'num_leaves': 70, 'objective': None, 'random_state': 123, 'reg_alpha': 0.0001, 'reg_lambda': 0.05, 'subsample': 1.0, 'subsample_for_bin': 200000, 'subsample_freq': 0, 'feature_fraction': 1.0, 'bagging_freq': 2, 'bagging_fraction': 0.6}
2023-11-02 19:54:51,495:INFO:Initializing predict_model()
2023-11-02 19:54:51,495:INFO:predict_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001856BE64130>, estimator=LGBMRegressor(bagging_fraction=0.6, bagging_freq=2, feature_fraction=1.0,
              learning_rate=0.15, min_child_samples=61, min_split_gain=0.8,
              n_estimators=90, n_jobs=-1, num_leaves=70, random_state=123,
              reg_alpha=0.0001, reg_lambda=0.05), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=False, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x000001856B3544C0>)
2023-11-02 19:54:51,495:INFO:Checking exceptions
2023-11-02 19:54:51,495:INFO:Preloading libraries
2023-11-02 19:54:52,218:INFO:_master_model_container: 3
2023-11-02 19:54:52,218:INFO:_display_container: 3
2023-11-02 19:54:52,219:INFO:LGBMRegressor(bagging_fraction=0.6, bagging_freq=2, feature_fraction=1.0,
              learning_rate=0.15, min_child_samples=61, min_split_gain=0.8,
              n_estimators=90, n_jobs=-1, num_leaves=70, random_state=123,
              reg_alpha=0.0001, reg_lambda=0.05)
2023-11-02 19:54:52,219:INFO:tune_model() successfully completed......................................
2023-11-02 20:19:34,155:INFO:PyCaret RegressionExperiment
2023-11-02 20:19:34,155:INFO:Logging name: model_rent_lgbm
2023-11-02 20:19:34,155:INFO:ML Usecase: MLUsecase.REGRESSION
2023-11-02 20:19:34,155:INFO:version 3.1.0
2023-11-02 20:19:34,155:INFO:Initializing setup()
2023-11-02 20:19:34,155:INFO:self.USI: 9564
2023-11-02 20:19:34,155:INFO:self._variable_keys: {'y_test', 'gpu_n_jobs_param', 'seed', 'exp_name_log', 'X_test', 'X', 'transform_target_param', 'X_train', 'exp_id', 'fold_groups_param', '_ml_usecase', 'memory', '_available_plots', 'idx', 'data', 'html_param', 'pipeline', 'y_train', 'logging_param', 'fold_generator', 'gpu_param', 'USI', 'fold_shuffle_param', 'log_plots_param', 'n_jobs_param', 'y', 'target_param'}
2023-11-02 20:19:34,156:INFO:Checking environment
2023-11-02 20:19:34,156:INFO:python_version: 3.8.5
2023-11-02 20:19:34,156:INFO:python_build: ('tags/v3.8.5:580fbb0', 'Jul 20 2020 15:57:54')
2023-11-02 20:19:34,156:INFO:machine: AMD64
2023-11-02 20:19:34,156:INFO:platform: Windows-10-10.0.19041-SP0
2023-11-02 20:19:34,175:INFO:Memory: svmem(total=137304428544, available=86680907776, percent=36.9, used=50623520768, free=86680907776)
2023-11-02 20:19:34,175:INFO:Physical Core: 16
2023-11-02 20:19:34,175:INFO:Logical Core: 32
2023-11-02 20:19:34,175:INFO:Checking libraries
2023-11-02 20:19:34,175:INFO:System:
2023-11-02 20:19:34,175:INFO:    python: 3.8.5 (tags/v3.8.5:580fbb0, Jul 20 2020, 15:57:54) [MSC v.1924 64 bit (AMD64)]
2023-11-02 20:19:34,175:INFO:executable: d:\trabajo\dmc\202311\pea da\pea_da\scripts\python.exe
2023-11-02 20:19:34,175:INFO:   machine: Windows-10-10.0.19041-SP0
2023-11-02 20:19:34,175:INFO:PyCaret required dependencies:
2023-11-02 20:19:34,175:INFO:                 pip: 20.1.1
2023-11-02 20:19:34,175:INFO:          setuptools: 47.1.0
2023-11-02 20:19:34,176:INFO:             pycaret: 3.1.0
2023-11-02 20:19:34,176:INFO:             IPython: 8.12.3
2023-11-02 20:19:34,176:INFO:          ipywidgets: 8.1.1
2023-11-02 20:19:34,176:INFO:                tqdm: 4.66.1
2023-11-02 20:19:34,176:INFO:               numpy: 1.23.5
2023-11-02 20:19:34,176:INFO:              pandas: 1.5.3
2023-11-02 20:19:34,176:INFO:              jinja2: 3.1.2
2023-11-02 20:19:34,176:INFO:               scipy: 1.10.1
2023-11-02 20:19:34,176:INFO:              joblib: 1.3.2
2023-11-02 20:19:34,176:INFO:             sklearn: 1.2.2
2023-11-02 20:19:34,176:INFO:                pyod: 1.1.1
2023-11-02 20:19:34,176:INFO:            imblearn: 0.11.0
2023-11-02 20:19:34,176:INFO:   category_encoders: 2.6.3
2023-11-02 20:19:34,176:INFO:            lightgbm: 4.1.0
2023-11-02 20:19:34,176:INFO:               numba: 0.58.1
2023-11-02 20:19:34,176:INFO:            requests: 2.31.0
2023-11-02 20:19:34,176:INFO:          matplotlib: 3.7.3
2023-11-02 20:19:34,176:INFO:          scikitplot: 0.3.7
2023-11-02 20:19:34,176:INFO:         yellowbrick: 1.5
2023-11-02 20:19:34,176:INFO:              plotly: 5.18.0
2023-11-02 20:19:34,176:INFO:    plotly-resampler: Not installed
2023-11-02 20:19:34,176:INFO:             kaleido: 0.2.1
2023-11-02 20:19:34,176:INFO:           schemdraw: 0.15
2023-11-02 20:19:34,176:INFO:         statsmodels: 0.14.0
2023-11-02 20:19:34,177:INFO:              sktime: 0.21.1
2023-11-02 20:19:34,177:INFO:               tbats: 1.1.3
2023-11-02 20:19:34,177:INFO:            pmdarima: 2.0.4
2023-11-02 20:19:34,177:INFO:              psutil: 5.9.6
2023-11-02 20:19:34,177:INFO:          markupsafe: 2.1.3
2023-11-02 20:19:34,177:INFO:             pickle5: Not installed
2023-11-02 20:19:34,177:INFO:         cloudpickle: 2.2.1
2023-11-02 20:19:34,177:INFO:         deprecation: 2.1.0
2023-11-02 20:19:34,177:INFO:              xxhash: 3.4.1
2023-11-02 20:19:34,177:INFO:           wurlitzer: Not installed
2023-11-02 20:19:34,177:INFO:PyCaret optional dependencies:
2023-11-02 20:19:34,177:INFO:                shap: Not installed
2023-11-02 20:19:34,177:INFO:           interpret: Not installed
2023-11-02 20:19:34,177:INFO:                umap: Not installed
2023-11-02 20:19:34,177:INFO:     ydata_profiling: Not installed
2023-11-02 20:19:34,177:INFO:  explainerdashboard: Not installed
2023-11-02 20:19:34,177:INFO:             autoviz: Not installed
2023-11-02 20:19:34,177:INFO:           fairlearn: Not installed
2023-11-02 20:19:34,177:INFO:          deepchecks: Not installed
2023-11-02 20:19:34,177:INFO:             xgboost: Not installed
2023-11-02 20:19:34,177:INFO:            catboost: Not installed
2023-11-02 20:19:34,177:INFO:              kmodes: Not installed
2023-11-02 20:19:34,177:INFO:             mlxtend: Not installed
2023-11-02 20:19:34,178:INFO:       statsforecast: Not installed
2023-11-02 20:19:34,178:INFO:        tune_sklearn: Not installed
2023-11-02 20:19:34,178:INFO:                 ray: Not installed
2023-11-02 20:19:34,178:INFO:            hyperopt: Not installed
2023-11-02 20:19:34,178:INFO:              optuna: Not installed
2023-11-02 20:19:34,178:INFO:               skopt: Not installed
2023-11-02 20:19:34,178:INFO:              mlflow: 2.8.0
2023-11-02 20:19:34,178:INFO:              gradio: Not installed
2023-11-02 20:19:34,178:INFO:             fastapi: Not installed
2023-11-02 20:19:34,178:INFO:             uvicorn: Not installed
2023-11-02 20:19:34,178:INFO:              m2cgen: Not installed
2023-11-02 20:19:34,178:INFO:           evidently: Not installed
2023-11-02 20:19:34,178:INFO:               fugue: Not installed
2023-11-02 20:19:34,178:INFO:           streamlit: Not installed
2023-11-02 20:19:34,178:INFO:             prophet: Not installed
2023-11-02 20:19:34,178:INFO:None
2023-11-02 20:19:34,178:INFO:Set up data.
2023-11-02 20:19:34,191:INFO:Set up folding strategy.
2023-11-02 20:19:34,191:INFO:Set up train/test split.
2023-11-02 20:19:34,198:INFO:Set up index.
2023-11-02 20:19:34,198:INFO:Assigning column types.
2023-11-02 20:19:34,201:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2023-11-02 20:19:34,201:INFO:Engine for model 'lasso' has not been set explicitly, hence returning None.
2023-11-02 20:19:34,207:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2023-11-02 20:19:34,213:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-11-02 20:19:34,282:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-11-02 20:19:34,336:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-11-02 20:19:34,336:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-11-02 20:19:34,337:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-11-02 20:19:34,337:INFO:Engine for model 'lasso' has not been set explicitly, hence returning None.
2023-11-02 20:19:34,343:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2023-11-02 20:19:34,348:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-11-02 20:19:34,417:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-11-02 20:19:34,471:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-11-02 20:19:34,472:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-11-02 20:19:34,472:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-11-02 20:19:34,472:INFO:Engine successfully changes for model 'lasso' to 'sklearn'.
2023-11-02 20:19:34,478:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2023-11-02 20:19:34,484:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-11-02 20:19:34,553:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-11-02 20:19:34,608:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-11-02 20:19:34,608:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-11-02 20:19:34,609:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-11-02 20:19:34,614:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2023-11-02 20:19:34,620:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-11-02 20:19:34,690:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-11-02 20:19:34,745:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-11-02 20:19:34,746:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-11-02 20:19:34,746:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-11-02 20:19:34,746:INFO:Engine successfully changes for model 'ridge' to 'sklearn'.
2023-11-02 20:19:34,757:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-11-02 20:19:34,828:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-11-02 20:19:34,882:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-11-02 20:19:34,883:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-11-02 20:19:34,883:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-11-02 20:19:34,895:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-11-02 20:19:34,966:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-11-02 20:19:35,020:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-11-02 20:19:35,021:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-11-02 20:19:35,021:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-11-02 20:19:35,022:INFO:Engine successfully changes for model 'en' to 'sklearn'.
2023-11-02 20:19:35,101:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-11-02 20:19:35,154:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-11-02 20:19:35,155:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-11-02 20:19:35,155:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-11-02 20:19:35,235:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-11-02 20:19:35,290:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-11-02 20:19:35,291:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-11-02 20:19:35,291:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-11-02 20:19:35,292:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2023-11-02 20:19:35,371:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-11-02 20:19:35,425:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-11-02 20:19:35,425:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-11-02 20:19:35,505:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-11-02 20:19:35,559:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-11-02 20:19:35,560:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-11-02 20:19:35,560:INFO:Engine successfully changes for model 'svm' to 'sklearn'.
2023-11-02 20:19:35,694:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-11-02 20:19:35,694:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-11-02 20:19:35,832:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-11-02 20:19:35,833:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-11-02 20:19:35,834:INFO:Preparing preprocessing pipeline...
2023-11-02 20:19:35,834:INFO:Set up simple imputation.
2023-11-02 20:19:35,838:INFO:Set up encoding of ordinal features.
2023-11-02 20:19:35,840:WARNING:The number of classes passed to feature Point of Contact in the ordinal_features parameter (2) don't match with the number of classes in the data (3).
2023-11-02 20:19:35,840:INFO:Set up encoding of categorical features.
2023-11-02 20:19:35,840:INFO:Set up column name cleaning.
2023-11-02 20:19:35,976:INFO:Finished creating preprocessing pipeline.
2023-11-02 20:19:36,002:INFO:Pipeline: Pipeline(memory=FastMemory(location=C:\Users\CHRIST~1\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['BHK', 'Size', 'Bathroom'],
                                    transformer=SimpleImputer())),
                ('categorical_imputer',
                 TransformerWrapper(include=['Area Type', 'City',
                                             'Furnishing Status',
                                             'Tenant Preferred',
                                             'Point of Contact'],
                                    transformer=SimpleImputer(strategy...
Contact Owner    1
NaN             -1
dtype: int64}]))),
                ('onehot_encoding',
                 TransformerWrapper(include=['Area Type', 'City',
                                             'Furnishing Status',
                                             'Tenant Preferred'],
                                    transformer=OneHotEncoder(cols=['Area Type',
                                                                    'City',
                                                                    'Furnishing '
                                                                    'Status',
                                                                    'Tenant '
                                                                    'Preferred'],
                                                              handle_missing='return_nan',
                                                              use_cat_names=True))),
                ('clean_column_names',
                 TransformerWrapper(transformer=CleanColumnNames()))])
2023-11-02 20:19:36,002:INFO:Creating final display dataframe.
2023-11-02 20:19:36,314:INFO:Setup _display_container:                     Description            Value
0                    Session id              123
1                        Target             Rent
2                   Target type       Regression
3           Original data shape       (4746, 12)
4        Transformed data shape       (4746, 20)
5   Transformed train set shape       (3322, 20)
6    Transformed test set shape       (1424, 20)
7               Ignore features                3
8              Ordinal features                1
9              Numeric features                3
10         Categorical features                5
11                   Preprocess             True
12              Imputation type           simple
13           Numeric imputation             mean
14       Categorical imputation             mode
15     Maximum one-hot encoding               25
16              Encoding method             None
17               Fold Generator            KFold
18                  Fold Number               10
19                     CPU Jobs               -1
20                      Use GPU            False
21               Log Experiment     MlflowLogger
22              Experiment Name  model_rent_lgbm
23                          USI             9564
2023-11-02 20:19:36,461:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-11-02 20:19:36,461:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-11-02 20:19:36,601:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-11-02 20:19:36,601:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-11-02 20:19:36,602:INFO:Logging experiment in loggers
2023-11-02 20:19:39,132:INFO:SubProcess save_model() called ==================================
2023-11-02 20:19:39,181:INFO:Initializing save_model()
2023-11-02 20:19:39,181:INFO:save_model(model=Pipeline(memory=FastMemory(location=C:\Users\CHRIST~1\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['BHK', 'Size', 'Bathroom'],
                                    transformer=SimpleImputer())),
                ('categorical_imputer',
                 TransformerWrapper(include=['Area Type', 'City',
                                             'Furnishing Status',
                                             'Tenant Preferred',
                                             'Point of Contact'],
                                    transformer=SimpleImputer(strategy...
Contact Owner    1
NaN             -1
dtype: int64}]))),
                ('onehot_encoding',
                 TransformerWrapper(include=['Area Type', 'City',
                                             'Furnishing Status',
                                             'Tenant Preferred'],
                                    transformer=OneHotEncoder(cols=['Area Type',
                                                                    'City',
                                                                    'Furnishing '
                                                                    'Status',
                                                                    'Tenant '
                                                                    'Preferred'],
                                                              handle_missing='return_nan',
                                                              use_cat_names=True))),
                ('clean_column_names',
                 TransformerWrapper(transformer=CleanColumnNames()))]), model_name=C:\Users\CHRIST~1\AppData\Local\Temp\tmptvhrgyz_\Transformation Pipeline, prep_pipe_=Pipeline(memory=FastMemory(location=C:\Users\CHRIST~1\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['BHK', 'Size', 'Bathroom'],
                                    transformer=SimpleImputer())),
                ('categorical_imputer',
                 TransformerWrapper(include=['Area Type', 'City',
                                             'Furnishing Status',
                                             'Tenant Preferred',
                                             'Point of Contact'],
                                    transformer=SimpleImputer(strategy...
Contact Owner    1
NaN             -1
dtype: int64}]))),
                ('onehot_encoding',
                 TransformerWrapper(include=['Area Type', 'City',
                                             'Furnishing Status',
                                             'Tenant Preferred'],
                                    transformer=OneHotEncoder(cols=['Area Type',
                                                                    'City',
                                                                    'Furnishing '
                                                                    'Status',
                                                                    'Tenant '
                                                                    'Preferred'],
                                                              handle_missing='return_nan',
                                                              use_cat_names=True))),
                ('clean_column_names',
                 TransformerWrapper(transformer=CleanColumnNames()))]), verbose=False, use_case=MLUsecase.REGRESSION, kwargs={})
2023-11-02 20:19:39,181:INFO:Adding model into prep_pipe
2023-11-02 20:19:39,181:WARNING:Only Model saved as it was a pipeline.
2023-11-02 20:19:39,189:INFO:C:\Users\CHRIST~1\AppData\Local\Temp\tmptvhrgyz_\Transformation Pipeline.pkl saved in current working directory
2023-11-02 20:19:39,213:INFO:Pipeline(memory=FastMemory(location=C:\Users\CHRIST~1\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['BHK', 'Size', 'Bathroom'],
                                    transformer=SimpleImputer())),
                ('categorical_imputer',
                 TransformerWrapper(include=['Area Type', 'City',
                                             'Furnishing Status',
                                             'Tenant Preferred',
                                             'Point of Contact'],
                                    transformer=SimpleImputer(strategy...
Contact Owner    1
NaN             -1
dtype: int64}]))),
                ('onehot_encoding',
                 TransformerWrapper(include=['Area Type', 'City',
                                             'Furnishing Status',
                                             'Tenant Preferred'],
                                    transformer=OneHotEncoder(cols=['Area Type',
                                                                    'City',
                                                                    'Furnishing '
                                                                    'Status',
                                                                    'Tenant '
                                                                    'Preferred'],
                                                              handle_missing='return_nan',
                                                              use_cat_names=True))),
                ('clean_column_names',
                 TransformerWrapper(transformer=CleanColumnNames()))])
2023-11-02 20:19:39,213:INFO:save_model() successfully completed......................................
2023-11-02 20:19:39,383:INFO:SubProcess save_model() end ==================================
2023-11-02 20:20:38,642:WARNING:d:\trabajo\dmc\202311\pea da\pea_da\lib\site-packages\joblib\_memmapping_reducer.py:598: UserWarning: Failed to delete temporary folder: C:\Users\CHRIST~1\AppData\Local\Temp\joblib_memmapping_folder_70624_e0a84bd365c74e3db2b97578509b6e85_62aa572df2d0486a9a644a1852c913a3
  warnings.warn("Failed to delete temporary folder: {}"

2023-11-02 20:20:38,642:WARNING:d:\trabajo\dmc\202311\pea da\pea_da\lib\site-packages\joblib\_memmapping_reducer.py:598: UserWarning: Failed to delete temporary folder: C:\Users\CHRIST~1\AppData\Local\Temp\joblib_memmapping_folder_70624_fc32b127c16440c0a8ad964c0065fa40_dd19a4eb683840128759c66f3a6ed0d6
  warnings.warn("Failed to delete temporary folder: {}"

2023-11-02 20:20:38,643:WARNING:d:\trabajo\dmc\202311\pea da\pea_da\lib\site-packages\joblib\_memmapping_reducer.py:598: UserWarning: Failed to delete temporary folder: C:\Users\CHRIST~1\AppData\Local\Temp\joblib_memmapping_folder_70624_e0a84bd365c74e3db2b97578509b6e85_746bdd93237549d5b5fdf04f353e46f2
  warnings.warn("Failed to delete temporary folder: {}"

2023-11-02 20:20:38,643:WARNING:d:\trabajo\dmc\202311\pea da\pea_da\lib\site-packages\joblib\_memmapping_reducer.py:598: UserWarning: Failed to delete temporary folder: C:\Users\CHRIST~1\AppData\Local\Temp\joblib_memmapping_folder_70624_934427877eab45af936cc83d3febea43_32ed85e34ac1453aa86dea6edfaab9b7
  warnings.warn("Failed to delete temporary folder: {}"

2023-11-02 20:20:38,643:WARNING:d:\trabajo\dmc\202311\pea da\pea_da\lib\site-packages\joblib\_memmapping_reducer.py:598: UserWarning: Failed to delete temporary folder: C:\Users\CHRIST~1\AppData\Local\Temp\joblib_memmapping_folder_70624_e0a84bd365c74e3db2b97578509b6e85_0d01751f02194b8881d92d28a434c2b8
  warnings.warn("Failed to delete temporary folder: {}"

2023-11-02 20:20:38,643:WARNING:d:\trabajo\dmc\202311\pea da\pea_da\lib\site-packages\joblib\_memmapping_reducer.py:598: UserWarning: Failed to delete temporary folder: C:\Users\CHRIST~1\AppData\Local\Temp\joblib_memmapping_folder_70624_c084a221641c44aebbfab91c696d002e_e3b579c9359944049c11c025fbc504fc
  warnings.warn("Failed to delete temporary folder: {}"

2023-11-02 20:20:38,643:WARNING:d:\trabajo\dmc\202311\pea da\pea_da\lib\site-packages\joblib\_memmapping_reducer.py:598: UserWarning: Failed to delete temporary folder: C:\Users\CHRIST~1\AppData\Local\Temp\joblib_memmapping_folder_70624_e0a84bd365c74e3db2b97578509b6e85_0acd04df151c400793d6eb60848ec219
  warnings.warn("Failed to delete temporary folder: {}"

2023-11-02 20:20:38,643:WARNING:d:\trabajo\dmc\202311\pea da\pea_da\lib\site-packages\joblib\_memmapping_reducer.py:598: UserWarning: Failed to delete temporary folder: C:\Users\CHRIST~1\AppData\Local\Temp\joblib_memmapping_folder_70624_e0a84bd365c74e3db2b97578509b6e85_9f89359cb14a4092b8705a40a870e2a3
  warnings.warn("Failed to delete temporary folder: {}"

2023-11-02 20:27:04,021:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-11-02 20:27:04,021:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-11-02 20:27:04,021:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-11-02 20:27:04,021:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-11-02 20:27:10,540:INFO:PyCaret RegressionExperiment
2023-11-02 20:27:10,540:INFO:Logging name: model_rent_lgbm
2023-11-02 20:27:10,540:INFO:ML Usecase: MLUsecase.REGRESSION
2023-11-02 20:27:10,540:INFO:version 3.1.0
2023-11-02 20:27:10,540:INFO:Initializing setup()
2023-11-02 20:27:10,540:INFO:self.USI: 33a8
2023-11-02 20:27:10,540:INFO:self._variable_keys: {'pipeline', 'html_param', 'USI', 'logging_param', 'memory', 'transform_target_param', 'fold_shuffle_param', 'y_train', 'data', 'X', 'X_train', 'y', 'target_param', 'idx', 'seed', 'exp_name_log', '_available_plots', 'y_test', 'gpu_param', 'fold_generator', 'gpu_n_jobs_param', '_ml_usecase', 'X_test', 'exp_id', 'log_plots_param', 'n_jobs_param', 'fold_groups_param'}
2023-11-02 20:27:10,540:INFO:Checking environment
2023-11-02 20:27:10,540:INFO:python_version: 3.8.5
2023-11-02 20:27:10,540:INFO:python_build: ('tags/v3.8.5:580fbb0', 'Jul 20 2020 15:57:54')
2023-11-02 20:27:10,540:INFO:machine: AMD64
2023-11-02 20:27:10,540:INFO:platform: Windows-10-10.0.19041-SP0
2023-11-02 20:27:10,558:INFO:Memory: svmem(total=137304428544, available=86651813888, percent=36.9, used=50652614656, free=86651813888)
2023-11-02 20:27:10,558:INFO:Physical Core: 16
2023-11-02 20:27:10,558:INFO:Logical Core: 32
2023-11-02 20:27:10,558:INFO:Checking libraries
2023-11-02 20:27:10,558:INFO:System:
2023-11-02 20:27:10,558:INFO:    python: 3.8.5 (tags/v3.8.5:580fbb0, Jul 20 2020, 15:57:54) [MSC v.1924 64 bit (AMD64)]
2023-11-02 20:27:10,558:INFO:executable: d:\trabajo\dmc\202311\pea da\pea_da\scripts\python.exe
2023-11-02 20:27:10,558:INFO:   machine: Windows-10-10.0.19041-SP0
2023-11-02 20:27:10,558:INFO:PyCaret required dependencies:
2023-11-02 20:27:10,578:INFO:                 pip: 20.1.1
2023-11-02 20:27:10,578:INFO:          setuptools: 47.1.0
2023-11-02 20:27:10,578:INFO:             pycaret: 3.1.0
2023-11-02 20:27:10,578:INFO:             IPython: 8.12.3
2023-11-02 20:27:10,578:INFO:          ipywidgets: 8.1.1
2023-11-02 20:27:10,578:INFO:                tqdm: 4.66.1
2023-11-02 20:27:10,578:INFO:               numpy: 1.23.5
2023-11-02 20:27:10,578:INFO:              pandas: 1.5.3
2023-11-02 20:27:10,578:INFO:              jinja2: 3.1.2
2023-11-02 20:27:10,578:INFO:               scipy: 1.10.1
2023-11-02 20:27:10,578:INFO:              joblib: 1.3.2
2023-11-02 20:27:10,578:INFO:             sklearn: 1.2.2
2023-11-02 20:27:10,578:INFO:                pyod: 1.1.1
2023-11-02 20:27:10,578:INFO:            imblearn: 0.11.0
2023-11-02 20:27:10,579:INFO:   category_encoders: 2.6.3
2023-11-02 20:27:10,579:INFO:            lightgbm: 4.1.0
2023-11-02 20:27:10,579:INFO:               numba: 0.58.1
2023-11-02 20:27:10,579:INFO:            requests: 2.31.0
2023-11-02 20:27:10,579:INFO:          matplotlib: 3.7.3
2023-11-02 20:27:10,579:INFO:          scikitplot: 0.3.7
2023-11-02 20:27:10,579:INFO:         yellowbrick: 1.5
2023-11-02 20:27:10,579:INFO:              plotly: 5.18.0
2023-11-02 20:27:10,579:INFO:    plotly-resampler: Not installed
2023-11-02 20:27:10,579:INFO:             kaleido: 0.2.1
2023-11-02 20:27:10,579:INFO:           schemdraw: 0.15
2023-11-02 20:27:10,579:INFO:         statsmodels: 0.14.0
2023-11-02 20:27:10,579:INFO:              sktime: 0.21.1
2023-11-02 20:27:10,579:INFO:               tbats: 1.1.3
2023-11-02 20:27:10,579:INFO:            pmdarima: 2.0.4
2023-11-02 20:27:10,579:INFO:              psutil: 5.9.6
2023-11-02 20:27:10,579:INFO:          markupsafe: 2.1.3
2023-11-02 20:27:10,579:INFO:             pickle5: Not installed
2023-11-02 20:27:10,579:INFO:         cloudpickle: 2.2.1
2023-11-02 20:27:10,579:INFO:         deprecation: 2.1.0
2023-11-02 20:27:10,579:INFO:              xxhash: 3.4.1
2023-11-02 20:27:10,579:INFO:           wurlitzer: Not installed
2023-11-02 20:27:10,579:INFO:PyCaret optional dependencies:
2023-11-02 20:27:10,591:INFO:                shap: Not installed
2023-11-02 20:27:10,591:INFO:           interpret: Not installed
2023-11-02 20:27:10,591:INFO:                umap: Not installed
2023-11-02 20:27:10,591:INFO:     ydata_profiling: Not installed
2023-11-02 20:27:10,591:INFO:  explainerdashboard: Not installed
2023-11-02 20:27:10,591:INFO:             autoviz: Not installed
2023-11-02 20:27:10,591:INFO:           fairlearn: Not installed
2023-11-02 20:27:10,591:INFO:          deepchecks: Not installed
2023-11-02 20:27:10,591:INFO:             xgboost: Not installed
2023-11-02 20:27:10,591:INFO:            catboost: Not installed
2023-11-02 20:27:10,591:INFO:              kmodes: Not installed
2023-11-02 20:27:10,591:INFO:             mlxtend: Not installed
2023-11-02 20:27:10,591:INFO:       statsforecast: Not installed
2023-11-02 20:27:10,591:INFO:        tune_sklearn: Not installed
2023-11-02 20:27:10,591:INFO:                 ray: Not installed
2023-11-02 20:27:10,591:INFO:            hyperopt: Not installed
2023-11-02 20:27:10,591:INFO:              optuna: Not installed
2023-11-02 20:27:10,591:INFO:               skopt: Not installed
2023-11-02 20:27:10,591:INFO:              mlflow: 2.8.0
2023-11-02 20:27:10,591:INFO:              gradio: Not installed
2023-11-02 20:27:10,591:INFO:             fastapi: Not installed
2023-11-02 20:27:10,591:INFO:             uvicorn: Not installed
2023-11-02 20:27:10,592:INFO:              m2cgen: Not installed
2023-11-02 20:27:10,592:INFO:           evidently: Not installed
2023-11-02 20:27:10,592:INFO:               fugue: Not installed
2023-11-02 20:27:10,592:INFO:           streamlit: Not installed
2023-11-02 20:27:10,592:INFO:             prophet: Not installed
2023-11-02 20:27:10,592:INFO:None
2023-11-02 20:27:10,592:INFO:Set up data.
2023-11-02 20:27:10,605:INFO:Set up folding strategy.
2023-11-02 20:27:10,605:INFO:Set up train/test split.
2023-11-02 20:27:10,612:INFO:Set up index.
2023-11-02 20:27:10,612:INFO:Assigning column types.
2023-11-02 20:27:10,616:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2023-11-02 20:27:10,616:INFO:Engine for model 'lasso' has not been set explicitly, hence returning None.
2023-11-02 20:27:10,622:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2023-11-02 20:27:10,627:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-11-02 20:27:10,697:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-11-02 20:27:10,750:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-11-02 20:27:10,751:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-11-02 20:27:10,751:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-11-02 20:27:10,752:INFO:Engine for model 'lasso' has not been set explicitly, hence returning None.
2023-11-02 20:27:10,757:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2023-11-02 20:27:10,763:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-11-02 20:27:10,833:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-11-02 20:27:10,887:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-11-02 20:27:10,888:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-11-02 20:27:10,888:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-11-02 20:27:10,889:INFO:Engine successfully changes for model 'lasso' to 'sklearn'.
2023-11-02 20:27:10,894:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2023-11-02 20:27:10,900:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-11-02 20:27:10,969:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-11-02 20:27:11,022:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-11-02 20:27:11,023:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-11-02 20:27:11,023:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-11-02 20:27:11,029:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2023-11-02 20:27:11,035:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-11-02 20:27:11,103:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-11-02 20:27:11,157:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-11-02 20:27:11,158:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-11-02 20:27:11,158:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-11-02 20:27:11,159:INFO:Engine successfully changes for model 'ridge' to 'sklearn'.
2023-11-02 20:27:11,170:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-11-02 20:27:11,239:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-11-02 20:27:11,295:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-11-02 20:27:11,295:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-11-02 20:27:11,295:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-11-02 20:27:11,307:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-11-02 20:27:11,377:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-11-02 20:27:11,429:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-11-02 20:27:11,430:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-11-02 20:27:11,430:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-11-02 20:27:11,431:INFO:Engine successfully changes for model 'en' to 'sklearn'.
2023-11-02 20:27:11,511:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-11-02 20:27:11,565:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-11-02 20:27:11,565:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-11-02 20:27:11,565:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-11-02 20:27:11,646:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-11-02 20:27:11,699:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-11-02 20:27:11,701:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-11-02 20:27:11,701:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-11-02 20:27:11,701:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2023-11-02 20:27:11,781:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-11-02 20:27:11,835:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-11-02 20:27:11,835:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-11-02 20:27:11,914:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-11-02 20:27:11,968:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-11-02 20:27:11,968:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-11-02 20:27:11,969:INFO:Engine successfully changes for model 'svm' to 'sklearn'.
2023-11-02 20:27:12,102:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-11-02 20:27:12,103:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-11-02 20:27:12,236:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-11-02 20:27:12,236:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-11-02 20:27:12,238:INFO:Preparing preprocessing pipeline...
2023-11-02 20:27:12,238:INFO:Set up simple imputation.
2023-11-02 20:27:12,242:INFO:Set up encoding of ordinal features.
2023-11-02 20:27:12,244:WARNING:The number of classes passed to feature Point of Contact in the ordinal_features parameter (2) don't match with the number of classes in the data (3).
2023-11-02 20:27:12,245:INFO:Set up encoding of categorical features.
2023-11-02 20:27:12,246:INFO:Set up column name cleaning.
2023-11-02 20:27:12,380:INFO:Finished creating preprocessing pipeline.
2023-11-02 20:27:12,409:INFO:Pipeline: Pipeline(memory=FastMemory(location=C:\Users\CHRIST~1\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['BHK', 'Size', 'Bathroom'],
                                    transformer=SimpleImputer())),
                ('categorical_imputer',
                 TransformerWrapper(include=['Area Type', 'City',
                                             'Furnishing Status',
                                             'Tenant Preferred',
                                             'Point of Contact'],
                                    transformer=SimpleImputer(strategy...
Contact Owner    1
NaN             -1
dtype: int64}]))),
                ('onehot_encoding',
                 TransformerWrapper(include=['Area Type', 'City',
                                             'Furnishing Status',
                                             'Tenant Preferred'],
                                    transformer=OneHotEncoder(cols=['Area Type',
                                                                    'City',
                                                                    'Furnishing '
                                                                    'Status',
                                                                    'Tenant '
                                                                    'Preferred'],
                                                              handle_missing='return_nan',
                                                              use_cat_names=True))),
                ('clean_column_names',
                 TransformerWrapper(transformer=CleanColumnNames()))])
2023-11-02 20:27:12,409:INFO:Creating final display dataframe.
2023-11-02 20:27:12,724:INFO:Setup _display_container:                     Description            Value
0                    Session id              123
1                        Target             Rent
2                   Target type       Regression
3           Original data shape       (4746, 12)
4        Transformed data shape       (4746, 20)
5   Transformed train set shape       (3322, 20)
6    Transformed test set shape       (1424, 20)
7               Ignore features                3
8              Ordinal features                1
9              Numeric features                3
10         Categorical features                5
11                   Preprocess             True
12              Imputation type           simple
13           Numeric imputation             mean
14       Categorical imputation             mode
15     Maximum one-hot encoding               25
16              Encoding method             None
17               Fold Generator            KFold
18                  Fold Number               10
19                     CPU Jobs               -1
20                      Use GPU            False
21               Log Experiment     MlflowLogger
22              Experiment Name  model_rent_lgbm
23                          USI             33a8
2023-11-02 20:27:12,870:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-11-02 20:27:12,871:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-11-02 20:27:13,007:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-11-02 20:27:13,008:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-11-02 20:27:13,011:INFO:Logging experiment in loggers
2023-11-02 20:27:15,135:INFO:SubProcess save_model() called ==================================
2023-11-02 20:27:15,184:INFO:Initializing save_model()
2023-11-02 20:27:15,185:INFO:save_model(model=Pipeline(memory=FastMemory(location=C:\Users\CHRIST~1\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['BHK', 'Size', 'Bathroom'],
                                    transformer=SimpleImputer())),
                ('categorical_imputer',
                 TransformerWrapper(include=['Area Type', 'City',
                                             'Furnishing Status',
                                             'Tenant Preferred',
                                             'Point of Contact'],
                                    transformer=SimpleImputer(strategy...
Contact Owner    1
NaN             -1
dtype: int64}]))),
                ('onehot_encoding',
                 TransformerWrapper(include=['Area Type', 'City',
                                             'Furnishing Status',
                                             'Tenant Preferred'],
                                    transformer=OneHotEncoder(cols=['Area Type',
                                                                    'City',
                                                                    'Furnishing '
                                                                    'Status',
                                                                    'Tenant '
                                                                    'Preferred'],
                                                              handle_missing='return_nan',
                                                              use_cat_names=True))),
                ('clean_column_names',
                 TransformerWrapper(transformer=CleanColumnNames()))]), model_name=C:\Users\CHRIST~1\AppData\Local\Temp\tmp9dvxyqov\Transformation Pipeline, prep_pipe_=Pipeline(memory=FastMemory(location=C:\Users\CHRIST~1\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['BHK', 'Size', 'Bathroom'],
                                    transformer=SimpleImputer())),
                ('categorical_imputer',
                 TransformerWrapper(include=['Area Type', 'City',
                                             'Furnishing Status',
                                             'Tenant Preferred',
                                             'Point of Contact'],
                                    transformer=SimpleImputer(strategy...
Contact Owner    1
NaN             -1
dtype: int64}]))),
                ('onehot_encoding',
                 TransformerWrapper(include=['Area Type', 'City',
                                             'Furnishing Status',
                                             'Tenant Preferred'],
                                    transformer=OneHotEncoder(cols=['Area Type',
                                                                    'City',
                                                                    'Furnishing '
                                                                    'Status',
                                                                    'Tenant '
                                                                    'Preferred'],
                                                              handle_missing='return_nan',
                                                              use_cat_names=True))),
                ('clean_column_names',
                 TransformerWrapper(transformer=CleanColumnNames()))]), verbose=False, use_case=MLUsecase.REGRESSION, kwargs={})
2023-11-02 20:27:15,185:INFO:Adding model into prep_pipe
2023-11-02 20:27:15,185:WARNING:Only Model saved as it was a pipeline.
2023-11-02 20:27:15,193:INFO:C:\Users\CHRIST~1\AppData\Local\Temp\tmp9dvxyqov\Transformation Pipeline.pkl saved in current working directory
2023-11-02 20:27:15,219:INFO:Pipeline(memory=FastMemory(location=C:\Users\CHRIST~1\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['BHK', 'Size', 'Bathroom'],
                                    transformer=SimpleImputer())),
                ('categorical_imputer',
                 TransformerWrapper(include=['Area Type', 'City',
                                             'Furnishing Status',
                                             'Tenant Preferred',
                                             'Point of Contact'],
                                    transformer=SimpleImputer(strategy...
Contact Owner    1
NaN             -1
dtype: int64}]))),
                ('onehot_encoding',
                 TransformerWrapper(include=['Area Type', 'City',
                                             'Furnishing Status',
                                             'Tenant Preferred'],
                                    transformer=OneHotEncoder(cols=['Area Type',
                                                                    'City',
                                                                    'Furnishing '
                                                                    'Status',
                                                                    'Tenant '
                                                                    'Preferred'],
                                                              handle_missing='return_nan',
                                                              use_cat_names=True))),
                ('clean_column_names',
                 TransformerWrapper(transformer=CleanColumnNames()))])
2023-11-02 20:27:15,219:INFO:save_model() successfully completed......................................
2023-11-02 20:27:15,329:INFO:SubProcess save_model() end ==================================
2023-11-02 20:27:17,080:INFO:setup() successfully completed in 2.79s...............
2023-11-02 20:27:27,482:INFO:Initializing create_model()
2023-11-02 20:27:27,482:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000019E77E410A0>, estimator=lightgbm, fold=None, round=4, cross_validation=True, predict=True, fit_kwargs=None, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=True, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, kwargs={})
2023-11-02 20:27:27,483:INFO:Checking exceptions
2023-11-02 20:27:27,499:INFO:Importing libraries
2023-11-02 20:27:27,499:INFO:Copying training dataset
2023-11-02 20:27:27,507:INFO:Defining folds
2023-11-02 20:27:27,507:INFO:Declaring metric variables
2023-11-02 20:27:27,511:INFO:Importing untrained model
2023-11-02 20:27:27,515:INFO:Light Gradient Boosting Machine Imported successfully
2023-11-02 20:27:27,522:INFO:Starting cross validation
2023-11-02 20:27:27,529:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-11-02 20:27:32,171:INFO:Calculating mean and std
2023-11-02 20:27:32,173:INFO:Creating metrics dataframe
2023-11-02 20:27:32,181:INFO:Finalizing model
2023-11-02 20:27:32,298:INFO:[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines
2023-11-02 20:27:32,300:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000784 seconds.
2023-11-02 20:27:32,301:INFO:You can set `force_row_wise=true` to remove the overhead.
2023-11-02 20:27:32,301:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2023-11-02 20:27:32,301:INFO:[LightGBM] [Info] Total Bins 282
2023-11-02 20:27:32,301:INFO:[LightGBM] [Info] Number of data points in the train set: 3322, number of used features: 18
2023-11-02 20:27:32,302:INFO:[LightGBM] [Info] Start training from score 34575.285370
2023-11-02 20:27:32,538:INFO:Creating Dashboard logs
2023-11-02 20:27:32,546:INFO:Model: Light Gradient Boosting Machine
2023-11-02 20:27:33,064:INFO:Logged params: {'boosting_type': 'gbdt', 'class_weight': None, 'colsample_bytree': 1.0, 'importance_type': 'split', 'learning_rate': 0.1, 'max_depth': -1, 'min_child_samples': 20, 'min_child_weight': 0.001, 'min_split_gain': 0.0, 'n_estimators': 100, 'n_jobs': -1, 'num_leaves': 31, 'objective': None, 'random_state': 123, 'reg_alpha': 0.0, 'reg_lambda': 0.0, 'subsample': 1.0, 'subsample_for_bin': 200000, 'subsample_freq': 0}
2023-11-02 20:27:36,785:INFO:Initializing predict_model()
2023-11-02 20:27:36,785:INFO:predict_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000019E77E410A0>, estimator=LGBMRegressor(n_jobs=-1, random_state=123), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=False, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x0000019E7A54DA60>)
2023-11-02 20:27:36,785:INFO:Checking exceptions
2023-11-02 20:27:36,785:INFO:Preloading libraries
2023-11-02 20:27:39,788:INFO:Uploading results into container
2023-11-02 20:27:39,789:INFO:Uploading model into container now
2023-11-02 20:27:39,799:INFO:_master_model_container: 1
2023-11-02 20:27:39,799:INFO:_display_container: 2
2023-11-02 20:27:39,800:INFO:LGBMRegressor(n_jobs=-1, random_state=123)
2023-11-02 20:27:39,800:INFO:create_model() successfully completed......................................
2023-11-02 20:27:39,939:INFO:Initializing tune_model()
2023-11-02 20:27:39,939:INFO:tune_model(estimator=LGBMRegressor(n_jobs=-1, random_state=123), fold=None, round=4, n_iter=20, custom_grid=None, optimize=R2, custom_scorer=None, search_library=scikit-learn, search_algorithm=None, early_stopping=False, early_stopping_max_iters=10, choose_better=True, fit_kwargs=None, groups=None, return_tuner=False, verbose=True, tuner_verbose=True, return_train_score=False, kwargs={}, self=<pycaret.regression.oop.RegressionExperiment object at 0x0000019E77E410A0>)
2023-11-02 20:27:39,939:INFO:Checking exceptions
2023-11-02 20:27:39,957:INFO:Copying training dataset
2023-11-02 20:27:39,961:INFO:Checking base model
2023-11-02 20:27:39,962:INFO:Base model : Light Gradient Boosting Machine
2023-11-02 20:27:39,967:INFO:Declaring metric variables
2023-11-02 20:27:39,970:INFO:Defining Hyperparameters
2023-11-02 20:27:40,096:INFO:Tuning with n_jobs=-1
2023-11-02 20:27:40,096:INFO:Initializing RandomizedSearchCV
2023-11-02 20:28:01,515:INFO:best_params: {'actual_estimator__reg_lambda': 0.05, 'actual_estimator__reg_alpha': 0.0001, 'actual_estimator__num_leaves': 70, 'actual_estimator__n_estimators': 90, 'actual_estimator__min_split_gain': 0.8, 'actual_estimator__min_child_samples': 61, 'actual_estimator__learning_rate': 0.15, 'actual_estimator__feature_fraction': 1.0, 'actual_estimator__bagging_freq': 2, 'actual_estimator__bagging_fraction': 0.6}
2023-11-02 20:28:01,516:INFO:Hyperparameter search completed
2023-11-02 20:28:01,516:INFO:SubProcess create_model() called ==================================
2023-11-02 20:28:01,517:INFO:Initializing create_model()
2023-11-02 20:28:01,517:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000019E77E410A0>, estimator=LGBMRegressor(n_jobs=-1, random_state=123), fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000019E139807F0>, model_only=True, return_train_score=False, kwargs={'reg_lambda': 0.05, 'reg_alpha': 0.0001, 'num_leaves': 70, 'n_estimators': 90, 'min_split_gain': 0.8, 'min_child_samples': 61, 'learning_rate': 0.15, 'feature_fraction': 1.0, 'bagging_freq': 2, 'bagging_fraction': 0.6})
2023-11-02 20:28:01,517:INFO:Checking exceptions
2023-11-02 20:28:01,517:INFO:Importing libraries
2023-11-02 20:28:01,518:INFO:Copying training dataset
2023-11-02 20:28:01,523:INFO:Defining folds
2023-11-02 20:28:01,523:INFO:Declaring metric variables
2023-11-02 20:28:01,527:INFO:Importing untrained model
2023-11-02 20:28:01,528:INFO:Declaring custom model
2023-11-02 20:28:01,532:INFO:Light Gradient Boosting Machine Imported successfully
2023-11-02 20:28:01,543:INFO:Starting cross validation
2023-11-02 20:28:01,545:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-11-02 20:28:02,433:INFO:Calculating mean and std
2023-11-02 20:28:02,435:INFO:Creating metrics dataframe
2023-11-02 20:28:02,442:INFO:Finalizing model
2023-11-02 20:28:02,554:INFO:[LightGBM] [Warning] feature_fraction is set=1.0, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1.0
2023-11-02 20:28:02,554:INFO:[LightGBM] [Warning] bagging_fraction is set=0.6, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6
2023-11-02 20:28:02,555:INFO:[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=0 will be ignored. Current value: bagging_freq=2
2023-11-02 20:28:02,557:INFO:[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines
2023-11-02 20:28:02,558:INFO:[LightGBM] [Warning] feature_fraction is set=1.0, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1.0
2023-11-02 20:28:02,558:INFO:[LightGBM] [Warning] bagging_fraction is set=0.6, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6
2023-11-02 20:28:02,558:INFO:[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=0 will be ignored. Current value: bagging_freq=2
2023-11-02 20:28:02,560:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000929 seconds.
2023-11-02 20:28:02,560:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-11-02 20:28:02,560:INFO:[LightGBM] [Info] Total Bins 282
2023-11-02 20:28:02,560:INFO:[LightGBM] [Info] Number of data points in the train set: 3322, number of used features: 18
2023-11-02 20:28:02,560:INFO:[LightGBM] [Info] Start training from score 34575.285370
2023-11-02 20:28:02,562:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-02 20:28:02,563:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-02 20:28:02,565:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-02 20:28:02,566:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-02 20:28:02,567:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-02 20:28:02,568:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-02 20:28:02,569:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-02 20:28:02,571:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-02 20:28:02,572:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-02 20:28:02,574:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-02 20:28:02,577:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-02 20:28:02,580:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-02 20:28:02,582:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-02 20:28:02,585:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-02 20:28:02,588:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-02 20:28:02,590:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-02 20:28:02,592:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-02 20:28:02,594:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-02 20:28:02,596:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-02 20:28:02,598:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-02 20:28:02,599:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-02 20:28:02,600:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-02 20:28:02,602:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-02 20:28:02,603:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-02 20:28:02,604:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-02 20:28:02,606:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-02 20:28:02,607:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-02 20:28:02,609:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-02 20:28:02,610:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-02 20:28:02,611:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-02 20:28:02,613:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-02 20:28:02,614:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-02 20:28:02,617:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-02 20:28:02,619:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-02 20:28:02,622:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-02 20:28:02,624:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-02 20:28:02,626:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-02 20:28:02,627:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-02 20:28:02,629:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-02 20:28:02,630:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-02 20:28:02,631:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-02 20:28:02,632:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-02 20:28:02,634:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-02 20:28:02,635:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-02 20:28:02,637:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-02 20:28:02,639:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-02 20:28:02,642:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-02 20:28:02,644:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-02 20:28:02,648:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-02 20:28:02,651:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-02 20:28:02,654:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-02 20:28:02,656:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-02 20:28:02,659:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-02 20:28:02,660:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-02 20:28:02,662:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-02 20:28:02,663:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-02 20:28:02,665:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-02 20:28:02,666:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-02 20:28:02,668:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-02 20:28:02,669:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-02 20:28:02,670:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-02 20:28:02,672:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-02 20:28:02,673:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-02 20:28:02,674:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-02 20:28:02,676:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-02 20:28:02,678:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-02 20:28:02,679:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-02 20:28:02,680:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-02 20:28:02,682:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-02 20:28:02,683:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-02 20:28:02,685:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-02 20:28:02,687:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-02 20:28:02,689:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-02 20:28:02,690:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-02 20:28:02,693:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-02 20:28:02,696:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-02 20:28:02,698:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-02 20:28:02,700:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-02 20:28:02,702:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-02 20:28:02,703:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-02 20:28:02,705:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-02 20:28:02,706:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-02 20:28:02,707:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-02 20:28:02,709:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-02 20:28:02,710:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-02 20:28:02,711:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-02 20:28:02,712:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-02 20:28:02,713:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-02 20:28:02,715:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-02 20:28:02,717:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-02 20:28:02,735:INFO:Uploading results into container
2023-11-02 20:28:02,737:INFO:Uploading model into container now
2023-11-02 20:28:02,738:INFO:_master_model_container: 2
2023-11-02 20:28:02,738:INFO:_display_container: 3
2023-11-02 20:28:02,739:INFO:LGBMRegressor(bagging_fraction=0.6, bagging_freq=2, feature_fraction=1.0,
              learning_rate=0.15, min_child_samples=61, min_split_gain=0.8,
              n_estimators=90, n_jobs=-1, num_leaves=70, random_state=123,
              reg_alpha=0.0001, reg_lambda=0.05)
2023-11-02 20:28:02,739:INFO:create_model() successfully completed......................................
2023-11-02 20:28:02,894:INFO:SubProcess create_model() end ==================================
2023-11-02 20:28:02,894:INFO:choose_better activated
2023-11-02 20:28:02,899:INFO:SubProcess create_model() called ==================================
2023-11-02 20:28:02,900:INFO:Initializing create_model()
2023-11-02 20:28:02,900:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000019E77E410A0>, estimator=LGBMRegressor(n_jobs=-1, random_state=123), fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, kwargs={})
2023-11-02 20:28:02,900:INFO:Checking exceptions
2023-11-02 20:28:02,902:INFO:Importing libraries
2023-11-02 20:28:02,903:INFO:Copying training dataset
2023-11-02 20:28:02,907:INFO:Defining folds
2023-11-02 20:28:02,908:INFO:Declaring metric variables
2023-11-02 20:28:02,908:INFO:Importing untrained model
2023-11-02 20:28:02,908:INFO:Declaring custom model
2023-11-02 20:28:02,909:INFO:Light Gradient Boosting Machine Imported successfully
2023-11-02 20:28:02,909:INFO:Starting cross validation
2023-11-02 20:28:02,911:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-11-02 20:28:04,086:INFO:Calculating mean and std
2023-11-02 20:28:04,087:INFO:Creating metrics dataframe
2023-11-02 20:28:04,089:INFO:Finalizing model
2023-11-02 20:28:04,190:INFO:[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines
2023-11-02 20:28:04,191:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000901 seconds.
2023-11-02 20:28:04,191:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-11-02 20:28:04,191:INFO:[LightGBM] [Info] Total Bins 282
2023-11-02 20:28:04,192:INFO:[LightGBM] [Info] Number of data points in the train set: 3322, number of used features: 18
2023-11-02 20:28:04,192:INFO:[LightGBM] [Info] Start training from score 34575.285370
2023-11-02 20:28:04,401:INFO:Uploading results into container
2023-11-02 20:28:04,402:INFO:Uploading model into container now
2023-11-02 20:28:04,402:INFO:_master_model_container: 3
2023-11-02 20:28:04,402:INFO:_display_container: 4
2023-11-02 20:28:04,403:INFO:LGBMRegressor(n_jobs=-1, random_state=123)
2023-11-02 20:28:04,403:INFO:create_model() successfully completed......................................
2023-11-02 20:28:04,543:INFO:SubProcess create_model() end ==================================
2023-11-02 20:28:04,543:INFO:LGBMRegressor(n_jobs=-1, random_state=123) result for R2 is 0.4826
2023-11-02 20:28:04,544:INFO:LGBMRegressor(bagging_fraction=0.6, bagging_freq=2, feature_fraction=1.0,
              learning_rate=0.15, min_child_samples=61, min_split_gain=0.8,
              n_estimators=90, n_jobs=-1, num_leaves=70, random_state=123,
              reg_alpha=0.0001, reg_lambda=0.05) result for R2 is 0.605
2023-11-02 20:28:04,545:INFO:LGBMRegressor(bagging_fraction=0.6, bagging_freq=2, feature_fraction=1.0,
              learning_rate=0.15, min_child_samples=61, min_split_gain=0.8,
              n_estimators=90, n_jobs=-1, num_leaves=70, random_state=123,
              reg_alpha=0.0001, reg_lambda=0.05) is best model
2023-11-02 20:28:04,545:INFO:choose_better completed
2023-11-02 20:28:04,545:INFO:Creating Dashboard logs
2023-11-02 20:28:04,550:INFO:Model: Light Gradient Boosting Machine
2023-11-02 20:28:05,075:INFO:Logged params: {'boosting_type': 'gbdt', 'class_weight': None, 'colsample_bytree': 1.0, 'importance_type': 'split', 'learning_rate': 0.15, 'max_depth': -1, 'min_child_samples': 61, 'min_child_weight': 0.001, 'min_split_gain': 0.8, 'n_estimators': 90, 'n_jobs': -1, 'num_leaves': 70, 'objective': None, 'random_state': 123, 'reg_alpha': 0.0001, 'reg_lambda': 0.05, 'subsample': 1.0, 'subsample_for_bin': 200000, 'subsample_freq': 0, 'feature_fraction': 1.0, 'bagging_freq': 2, 'bagging_fraction': 0.6}
2023-11-02 20:28:08,463:INFO:Initializing predict_model()
2023-11-02 20:28:08,463:INFO:predict_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000019E77E410A0>, estimator=LGBMRegressor(bagging_fraction=0.6, bagging_freq=2, feature_fraction=1.0,
              learning_rate=0.15, min_child_samples=61, min_split_gain=0.8,
              n_estimators=90, n_jobs=-1, num_leaves=70, random_state=123,
              reg_alpha=0.0001, reg_lambda=0.05), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=False, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x0000019E78481550>)
2023-11-02 20:28:08,463:INFO:Checking exceptions
2023-11-02 20:28:08,463:INFO:Preloading libraries
2023-11-02 20:28:11,480:INFO:_master_model_container: 3
2023-11-02 20:28:11,481:INFO:_display_container: 3
2023-11-02 20:28:11,482:INFO:LGBMRegressor(bagging_fraction=0.6, bagging_freq=2, feature_fraction=1.0,
              learning_rate=0.15, min_child_samples=61, min_split_gain=0.8,
              n_estimators=90, n_jobs=-1, num_leaves=70, random_state=123,
              reg_alpha=0.0001, reg_lambda=0.05)
2023-11-02 20:28:11,482:INFO:tune_model() successfully completed......................................
2023-11-02 22:07:27,225:WARNING:d:\trabajo\dmc\202311\pea da\pea_da\lib\site-packages\joblib\_memmapping_reducer.py:598: UserWarning: Failed to delete temporary folder: C:\Users\CHRIST~1\AppData\Local\Temp\joblib_memmapping_folder_74608_3647523145ee461f9be3d2c08be6dfde_ab241b174acf469e9b9963d3e42f0659
  warnings.warn("Failed to delete temporary folder: {}"

2023-11-02 22:07:27,225:WARNING:d:\trabajo\dmc\202311\pea da\pea_da\lib\site-packages\joblib\_memmapping_reducer.py:598: UserWarning: Failed to delete temporary folder: C:\Users\CHRIST~1\AppData\Local\Temp\joblib_memmapping_folder_74608_e7c81feab9784237818a72c1d24375ff_04d3324e36664980b689a926b55f3966
  warnings.warn("Failed to delete temporary folder: {}"

2023-11-02 22:07:27,226:WARNING:d:\trabajo\dmc\202311\pea da\pea_da\lib\site-packages\joblib\_memmapping_reducer.py:598: UserWarning: Failed to delete temporary folder: C:\Users\CHRIST~1\AppData\Local\Temp\joblib_memmapping_folder_74608_3647523145ee461f9be3d2c08be6dfde_03f62454e0e647668338035bc9b69368
  warnings.warn("Failed to delete temporary folder: {}"

2023-11-02 22:07:27,226:WARNING:d:\trabajo\dmc\202311\pea da\pea_da\lib\site-packages\joblib\_memmapping_reducer.py:598: UserWarning: Failed to delete temporary folder: C:\Users\CHRIST~1\AppData\Local\Temp\joblib_memmapping_folder_74608_5206b1daf070410a9dd9e8fe68f90d26_94b095f456b14b44a8fb3fe12a60cf77
  warnings.warn("Failed to delete temporary folder: {}"

2023-11-02 22:07:27,226:WARNING:d:\trabajo\dmc\202311\pea da\pea_da\lib\site-packages\joblib\_memmapping_reducer.py:598: UserWarning: Failed to delete temporary folder: C:\Users\CHRIST~1\AppData\Local\Temp\joblib_memmapping_folder_74608_3647523145ee461f9be3d2c08be6dfde_9969917bdb3b4b63b5a2cc1e2c57bdc5
  warnings.warn("Failed to delete temporary folder: {}"

2023-11-02 22:07:27,226:WARNING:d:\trabajo\dmc\202311\pea da\pea_da\lib\site-packages\joblib\_memmapping_reducer.py:598: UserWarning: Failed to delete temporary folder: C:\Users\CHRIST~1\AppData\Local\Temp\joblib_memmapping_folder_74608_fa668de1ceda45d0ae663b61fc9d2d35_29f622583c204b2da76d5bc799083c5b
  warnings.warn("Failed to delete temporary folder: {}"

2023-11-02 22:07:27,226:WARNING:d:\trabajo\dmc\202311\pea da\pea_da\lib\site-packages\joblib\_memmapping_reducer.py:598: UserWarning: Failed to delete temporary folder: C:\Users\CHRIST~1\AppData\Local\Temp\joblib_memmapping_folder_74608_3647523145ee461f9be3d2c08be6dfde_a1ce173794c6429f9144ca5318f2e393
  warnings.warn("Failed to delete temporary folder: {}"

2023-11-02 22:07:27,226:WARNING:d:\trabajo\dmc\202311\pea da\pea_da\lib\site-packages\joblib\_memmapping_reducer.py:598: UserWarning: Failed to delete temporary folder: C:\Users\CHRIST~1\AppData\Local\Temp\joblib_memmapping_folder_74608_3647523145ee461f9be3d2c08be6dfde_0a45dc6b2c104cc29d8a29d7d09e50af
  warnings.warn("Failed to delete temporary folder: {}"

